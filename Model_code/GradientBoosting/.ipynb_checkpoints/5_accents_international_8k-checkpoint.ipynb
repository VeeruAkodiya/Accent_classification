{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f1f68c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "110438f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import IPython.display as ipd\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import random\n",
    "import pandas as pd\n",
    "from statistics import mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "058d4080",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_json('../5_accent_features_8k.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a24526a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lable</th>\n",
       "      <th>rms</th>\n",
       "      <th>zrc</th>\n",
       "      <th>sb</th>\n",
       "      <th>sc</th>\n",
       "      <th>mfcc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>american</td>\n",
       "      <td>[0.10995900630000001, 0.123431541, 0.057550724...</td>\n",
       "      <td>[0.1611328125, 0.2001953125, 0.2119140625, 0.3...</td>\n",
       "      <td>[982.3833614816, 998.6809827277, 1227.21971388...</td>\n",
       "      <td>[1026.7194059383, 921.3751421883, 1687.1791594...</td>\n",
       "      <td>[[-132.202331543, -106.4561920166, -144.163803...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>american</td>\n",
       "      <td>[0.0449587628, 0.0892027393, 0.0972395092, 0.1...</td>\n",
       "      <td>[0.208984375, 0.310546875, 0.1513671875, 0.100...</td>\n",
       "      <td>[963.9106217367, 897.3924172554, 900.666981819...</td>\n",
       "      <td>[1576.1782294645, 1341.2154906595, 1251.823100...</td>\n",
       "      <td>[[-120.1662216187, -64.2591247559, -84.6273498...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>american</td>\n",
       "      <td>[0.0351665355, 0.10262352970000001, 0.10095142...</td>\n",
       "      <td>[0.078125, 0.12109375, 0.064453125, 0.07128906...</td>\n",
       "      <td>[923.2569985211, 954.1517268996, 936.182168068...</td>\n",
       "      <td>[729.6191839967, 906.2135315307, 772.504023950...</td>\n",
       "      <td>[[-204.3710479736, -111.2505950928, -130.19665...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>indian</td>\n",
       "      <td>[0.058094892700000005, 0.0720619857, 0.0426379...</td>\n",
       "      <td>[0.1396484375, 0.171875, 0.0625, 0.0673828125,...</td>\n",
       "      <td>[1126.3458385918, 1075.1604486286, 916.9369396...</td>\n",
       "      <td>[1119.0037267103, 1001.3589439764, 686.3549935...</td>\n",
       "      <td>[[-204.9865570068, -181.3363800049, -285.47653...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>american</td>\n",
       "      <td>[0.0127645116, 0.055047065000000006, 0.0553400...</td>\n",
       "      <td>[0.1171875, 0.158203125, 0.0517578125, 0.04492...</td>\n",
       "      <td>[945.6208621592, 965.5379844122, 939.509883464...</td>\n",
       "      <td>[576.6528108766, 952.5287575697, 825.655844384...</td>\n",
       "      <td>[[-238.695098877, -131.825668335, -140.2941741...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11125</th>\n",
       "      <td>indian</td>\n",
       "      <td>[0.005203237800000001, 0.0583481714, 0.0883544...</td>\n",
       "      <td>[0.1484375, 0.1748046875, 0.0546875, 0.0595703...</td>\n",
       "      <td>[939.0655020602, 735.4849804102, 842.864382448...</td>\n",
       "      <td>[1085.5789562353, 633.6020721972, 746.87798516...</td>\n",
       "      <td>[[-392.308380127, -253.5061950684, -204.861923...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11126</th>\n",
       "      <td>british</td>\n",
       "      <td>[0.0670182556, 0.11963738500000001, 0.13444279...</td>\n",
       "      <td>[0.0966796875, 0.140625, 0.072265625, 0.056640...</td>\n",
       "      <td>[279.7990742638, 691.1704207535, 1057.99920323...</td>\n",
       "      <td>[334.4932575184, 602.9638842564, 910.891398897...</td>\n",
       "      <td>[[-296.3085021973, -209.2213897705, -214.50019...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11127</th>\n",
       "      <td>australian</td>\n",
       "      <td>[0.0458770357, 0.06701447070000001, 0.05166622...</td>\n",
       "      <td>[0.0791015625, 0.11328125, 0.2255859375, 0.267...</td>\n",
       "      <td>[889.8696890516, 1050.0291055209, 1192.2407333...</td>\n",
       "      <td>[831.469767543, 1120.86074567, 963.4700761504,...</td>\n",
       "      <td>[[-158.1745147705, -105.2735824585, -136.48347...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11128</th>\n",
       "      <td>american</td>\n",
       "      <td>[0.1035422683, 0.1399547011, 0.0942250416, 0.0...</td>\n",
       "      <td>[0.11523437500000001, 0.1923828125, 0.23339843...</td>\n",
       "      <td>[578.4063870442, 687.3923714443, 871.801319026...</td>\n",
       "      <td>[740.7449395003, 995.2480438369, 1025.91691399...</td>\n",
       "      <td>[[-106.186164856, -56.3407363892, -119.2368698...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11129</th>\n",
       "      <td>indian</td>\n",
       "      <td>[0.0143631678, 0.0487043858, 0.0869188607, 0.1...</td>\n",
       "      <td>[0.12890625, 0.1630859375, 0.0751953125, 0.066...</td>\n",
       "      <td>[612.8867126285, 632.5646167517, 743.737460231...</td>\n",
       "      <td>[406.2776748625, 455.8883271732, 818.600459216...</td>\n",
       "      <td>[[-472.9836425781, -234.4741210938, -170.09353...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11130 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            lable                                                rms  \\\n",
       "0        american  [0.10995900630000001, 0.123431541, 0.057550724...   \n",
       "1        american  [0.0449587628, 0.0892027393, 0.0972395092, 0.1...   \n",
       "2        american  [0.0351665355, 0.10262352970000001, 0.10095142...   \n",
       "3          indian  [0.058094892700000005, 0.0720619857, 0.0426379...   \n",
       "4        american  [0.0127645116, 0.055047065000000006, 0.0553400...   \n",
       "...           ...                                                ...   \n",
       "11125      indian  [0.005203237800000001, 0.0583481714, 0.0883544...   \n",
       "11126     british  [0.0670182556, 0.11963738500000001, 0.13444279...   \n",
       "11127  australian  [0.0458770357, 0.06701447070000001, 0.05166622...   \n",
       "11128    american  [0.1035422683, 0.1399547011, 0.0942250416, 0.0...   \n",
       "11129      indian  [0.0143631678, 0.0487043858, 0.0869188607, 0.1...   \n",
       "\n",
       "                                                     zrc  \\\n",
       "0      [0.1611328125, 0.2001953125, 0.2119140625, 0.3...   \n",
       "1      [0.208984375, 0.310546875, 0.1513671875, 0.100...   \n",
       "2      [0.078125, 0.12109375, 0.064453125, 0.07128906...   \n",
       "3      [0.1396484375, 0.171875, 0.0625, 0.0673828125,...   \n",
       "4      [0.1171875, 0.158203125, 0.0517578125, 0.04492...   \n",
       "...                                                  ...   \n",
       "11125  [0.1484375, 0.1748046875, 0.0546875, 0.0595703...   \n",
       "11126  [0.0966796875, 0.140625, 0.072265625, 0.056640...   \n",
       "11127  [0.0791015625, 0.11328125, 0.2255859375, 0.267...   \n",
       "11128  [0.11523437500000001, 0.1923828125, 0.23339843...   \n",
       "11129  [0.12890625, 0.1630859375, 0.0751953125, 0.066...   \n",
       "\n",
       "                                                      sb  \\\n",
       "0      [982.3833614816, 998.6809827277, 1227.21971388...   \n",
       "1      [963.9106217367, 897.3924172554, 900.666981819...   \n",
       "2      [923.2569985211, 954.1517268996, 936.182168068...   \n",
       "3      [1126.3458385918, 1075.1604486286, 916.9369396...   \n",
       "4      [945.6208621592, 965.5379844122, 939.509883464...   \n",
       "...                                                  ...   \n",
       "11125  [939.0655020602, 735.4849804102, 842.864382448...   \n",
       "11126  [279.7990742638, 691.1704207535, 1057.99920323...   \n",
       "11127  [889.8696890516, 1050.0291055209, 1192.2407333...   \n",
       "11128  [578.4063870442, 687.3923714443, 871.801319026...   \n",
       "11129  [612.8867126285, 632.5646167517, 743.737460231...   \n",
       "\n",
       "                                                      sc  \\\n",
       "0      [1026.7194059383, 921.3751421883, 1687.1791594...   \n",
       "1      [1576.1782294645, 1341.2154906595, 1251.823100...   \n",
       "2      [729.6191839967, 906.2135315307, 772.504023950...   \n",
       "3      [1119.0037267103, 1001.3589439764, 686.3549935...   \n",
       "4      [576.6528108766, 952.5287575697, 825.655844384...   \n",
       "...                                                  ...   \n",
       "11125  [1085.5789562353, 633.6020721972, 746.87798516...   \n",
       "11126  [334.4932575184, 602.9638842564, 910.891398897...   \n",
       "11127  [831.469767543, 1120.86074567, 963.4700761504,...   \n",
       "11128  [740.7449395003, 995.2480438369, 1025.91691399...   \n",
       "11129  [406.2776748625, 455.8883271732, 818.600459216...   \n",
       "\n",
       "                                                    mfcc  \n",
       "0      [[-132.202331543, -106.4561920166, -144.163803...  \n",
       "1      [[-120.1662216187, -64.2591247559, -84.6273498...  \n",
       "2      [[-204.3710479736, -111.2505950928, -130.19665...  \n",
       "3      [[-204.9865570068, -181.3363800049, -285.47653...  \n",
       "4      [[-238.695098877, -131.825668335, -140.2941741...  \n",
       "...                                                  ...  \n",
       "11125  [[-392.308380127, -253.5061950684, -204.861923...  \n",
       "11126  [[-296.3085021973, -209.2213897705, -214.50019...  \n",
       "11127  [[-158.1745147705, -105.2735824585, -136.48347...  \n",
       "11128  [[-106.186164856, -56.3407363892, -119.2368698...  \n",
       "11129  [[-472.9836425781, -234.4741210938, -170.09353...  \n",
       "\n",
       "[11130 rows x 6 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fbd1f5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_min_avg_max_std(column, data=data):\n",
    "    row_data_min, row_data_avg, row_data_max, row_data_std = [], [], [], []\n",
    "    for row in data[column]:\n",
    "        row_data_min.append(min(row))\n",
    "        row_data_avg.append(mean(row))\n",
    "        row_data_max.append(max(row))\n",
    "        row_data_std.append(np.std(row))\n",
    "    \n",
    "    data.drop(column, axis=1, inplace=True)\n",
    "    data[f'min_{column}'] = row_data_min\n",
    "    data[f'avg_{column}'] = row_data_avg\n",
    "    data[f'max_{column}'] = row_data_max\n",
    "    data[f'std_{column}'] = row_data_std\n",
    "    \n",
    "    return row_data_min, row_data_avg, row_data_max, row_data_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08903337",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_min_avg_max_std('rms')\n",
    "get_min_avg_max_std('zrc')\n",
    "get_min_avg_max_std('sb')\n",
    "_ = get_min_avg_max_std('sc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4eb85588",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lable</th>\n",
       "      <th>min_rms</th>\n",
       "      <th>avg_rms</th>\n",
       "      <th>max_rms</th>\n",
       "      <th>std_rms</th>\n",
       "      <th>min_zrc</th>\n",
       "      <th>avg_zrc</th>\n",
       "      <th>max_zrc</th>\n",
       "      <th>std_zrc</th>\n",
       "      <th>min_sb</th>\n",
       "      <th>avg_sb</th>\n",
       "      <th>max_sb</th>\n",
       "      <th>std_sb</th>\n",
       "      <th>min_sc</th>\n",
       "      <th>avg_sc</th>\n",
       "      <th>max_sc</th>\n",
       "      <th>std_sc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>american</td>\n",
       "      <td>0.001167</td>\n",
       "      <td>0.103407</td>\n",
       "      <td>0.189941</td>\n",
       "      <td>0.047770</td>\n",
       "      <td>0.067383</td>\n",
       "      <td>0.189209</td>\n",
       "      <td>0.440430</td>\n",
       "      <td>0.094806</td>\n",
       "      <td>394.431290</td>\n",
       "      <td>880.691752</td>\n",
       "      <td>1307.266225</td>\n",
       "      <td>245.430824</td>\n",
       "      <td>434.735910</td>\n",
       "      <td>1009.641142</td>\n",
       "      <td>2161.378419</td>\n",
       "      <td>416.130162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>american</td>\n",
       "      <td>0.000801</td>\n",
       "      <td>0.058658</td>\n",
       "      <td>0.103927</td>\n",
       "      <td>0.031081</td>\n",
       "      <td>0.079102</td>\n",
       "      <td>0.212576</td>\n",
       "      <td>0.539062</td>\n",
       "      <td>0.115285</td>\n",
       "      <td>480.439854</td>\n",
       "      <td>870.267340</td>\n",
       "      <td>1122.283493</td>\n",
       "      <td>160.383675</td>\n",
       "      <td>422.148634</td>\n",
       "      <td>1097.386582</td>\n",
       "      <td>2123.551926</td>\n",
       "      <td>451.090306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>american</td>\n",
       "      <td>0.000754</td>\n",
       "      <td>0.067203</td>\n",
       "      <td>0.109837</td>\n",
       "      <td>0.031252</td>\n",
       "      <td>0.047852</td>\n",
       "      <td>0.204605</td>\n",
       "      <td>0.706055</td>\n",
       "      <td>0.200368</td>\n",
       "      <td>448.441120</td>\n",
       "      <td>828.700336</td>\n",
       "      <td>1435.614128</td>\n",
       "      <td>246.024383</td>\n",
       "      <td>291.909819</td>\n",
       "      <td>991.248812</td>\n",
       "      <td>2980.423978</td>\n",
       "      <td>688.983759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>indian</td>\n",
       "      <td>0.001090</td>\n",
       "      <td>0.056282</td>\n",
       "      <td>0.122838</td>\n",
       "      <td>0.031935</td>\n",
       "      <td>0.056641</td>\n",
       "      <td>0.161513</td>\n",
       "      <td>0.534180</td>\n",
       "      <td>0.120783</td>\n",
       "      <td>436.448730</td>\n",
       "      <td>899.991063</td>\n",
       "      <td>1271.609599</td>\n",
       "      <td>213.625065</td>\n",
       "      <td>369.349090</td>\n",
       "      <td>1044.968954</td>\n",
       "      <td>2045.723166</td>\n",
       "      <td>404.911227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>american</td>\n",
       "      <td>0.005269</td>\n",
       "      <td>0.055942</td>\n",
       "      <td>0.114724</td>\n",
       "      <td>0.029470</td>\n",
       "      <td>0.044922</td>\n",
       "      <td>0.132704</td>\n",
       "      <td>0.386719</td>\n",
       "      <td>0.085825</td>\n",
       "      <td>547.596459</td>\n",
       "      <td>1014.481168</td>\n",
       "      <td>1391.435266</td>\n",
       "      <td>217.824753</td>\n",
       "      <td>395.814580</td>\n",
       "      <td>1026.078903</td>\n",
       "      <td>2352.828746</td>\n",
       "      <td>413.301996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11125</th>\n",
       "      <td>indian</td>\n",
       "      <td>0.000496</td>\n",
       "      <td>0.051814</td>\n",
       "      <td>0.105858</td>\n",
       "      <td>0.028519</td>\n",
       "      <td>0.054688</td>\n",
       "      <td>0.196100</td>\n",
       "      <td>0.597656</td>\n",
       "      <td>0.134253</td>\n",
       "      <td>407.614581</td>\n",
       "      <td>888.767232</td>\n",
       "      <td>1286.562931</td>\n",
       "      <td>199.557633</td>\n",
       "      <td>327.117005</td>\n",
       "      <td>1075.957907</td>\n",
       "      <td>2119.978221</td>\n",
       "      <td>489.302061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11126</th>\n",
       "      <td>british</td>\n",
       "      <td>0.010991</td>\n",
       "      <td>0.076711</td>\n",
       "      <td>0.134443</td>\n",
       "      <td>0.036779</td>\n",
       "      <td>0.046875</td>\n",
       "      <td>0.142241</td>\n",
       "      <td>0.453125</td>\n",
       "      <td>0.105300</td>\n",
       "      <td>279.799074</td>\n",
       "      <td>837.773872</td>\n",
       "      <td>1161.597266</td>\n",
       "      <td>204.123944</td>\n",
       "      <td>334.493258</td>\n",
       "      <td>889.486936</td>\n",
       "      <td>2626.316454</td>\n",
       "      <td>469.690909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11127</th>\n",
       "      <td>australian</td>\n",
       "      <td>0.006336</td>\n",
       "      <td>0.063076</td>\n",
       "      <td>0.114340</td>\n",
       "      <td>0.028879</td>\n",
       "      <td>0.035156</td>\n",
       "      <td>0.144206</td>\n",
       "      <td>0.616211</td>\n",
       "      <td>0.134536</td>\n",
       "      <td>715.505224</td>\n",
       "      <td>988.036607</td>\n",
       "      <td>1311.033228</td>\n",
       "      <td>145.070914</td>\n",
       "      <td>566.711898</td>\n",
       "      <td>1066.883145</td>\n",
       "      <td>2340.979582</td>\n",
       "      <td>460.148163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11128</th>\n",
       "      <td>american</td>\n",
       "      <td>0.005160</td>\n",
       "      <td>0.094933</td>\n",
       "      <td>0.188103</td>\n",
       "      <td>0.061273</td>\n",
       "      <td>0.073242</td>\n",
       "      <td>0.219238</td>\n",
       "      <td>0.410156</td>\n",
       "      <td>0.117426</td>\n",
       "      <td>471.818934</td>\n",
       "      <td>809.624811</td>\n",
       "      <td>1178.005456</td>\n",
       "      <td>214.518913</td>\n",
       "      <td>651.189324</td>\n",
       "      <td>1095.364001</td>\n",
       "      <td>1907.227408</td>\n",
       "      <td>411.637243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11129</th>\n",
       "      <td>indian</td>\n",
       "      <td>0.000523</td>\n",
       "      <td>0.062909</td>\n",
       "      <td>0.127007</td>\n",
       "      <td>0.033762</td>\n",
       "      <td>0.060547</td>\n",
       "      <td>0.182408</td>\n",
       "      <td>0.486328</td>\n",
       "      <td>0.117248</td>\n",
       "      <td>465.102776</td>\n",
       "      <td>819.474318</td>\n",
       "      <td>1156.474441</td>\n",
       "      <td>165.770772</td>\n",
       "      <td>406.277675</td>\n",
       "      <td>1022.974252</td>\n",
       "      <td>2009.081023</td>\n",
       "      <td>378.511378</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11130 rows Ã— 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            lable   min_rms   avg_rms   max_rms   std_rms   min_zrc   avg_zrc  \\\n",
       "0        american  0.001167  0.103407  0.189941  0.047770  0.067383  0.189209   \n",
       "1        american  0.000801  0.058658  0.103927  0.031081  0.079102  0.212576   \n",
       "2        american  0.000754  0.067203  0.109837  0.031252  0.047852  0.204605   \n",
       "3          indian  0.001090  0.056282  0.122838  0.031935  0.056641  0.161513   \n",
       "4        american  0.005269  0.055942  0.114724  0.029470  0.044922  0.132704   \n",
       "...           ...       ...       ...       ...       ...       ...       ...   \n",
       "11125      indian  0.000496  0.051814  0.105858  0.028519  0.054688  0.196100   \n",
       "11126     british  0.010991  0.076711  0.134443  0.036779  0.046875  0.142241   \n",
       "11127  australian  0.006336  0.063076  0.114340  0.028879  0.035156  0.144206   \n",
       "11128    american  0.005160  0.094933  0.188103  0.061273  0.073242  0.219238   \n",
       "11129      indian  0.000523  0.062909  0.127007  0.033762  0.060547  0.182408   \n",
       "\n",
       "        max_zrc   std_zrc      min_sb       avg_sb       max_sb      std_sb  \\\n",
       "0      0.440430  0.094806  394.431290   880.691752  1307.266225  245.430824   \n",
       "1      0.539062  0.115285  480.439854   870.267340  1122.283493  160.383675   \n",
       "2      0.706055  0.200368  448.441120   828.700336  1435.614128  246.024383   \n",
       "3      0.534180  0.120783  436.448730   899.991063  1271.609599  213.625065   \n",
       "4      0.386719  0.085825  547.596459  1014.481168  1391.435266  217.824753   \n",
       "...         ...       ...         ...          ...          ...         ...   \n",
       "11125  0.597656  0.134253  407.614581   888.767232  1286.562931  199.557633   \n",
       "11126  0.453125  0.105300  279.799074   837.773872  1161.597266  204.123944   \n",
       "11127  0.616211  0.134536  715.505224   988.036607  1311.033228  145.070914   \n",
       "11128  0.410156  0.117426  471.818934   809.624811  1178.005456  214.518913   \n",
       "11129  0.486328  0.117248  465.102776   819.474318  1156.474441  165.770772   \n",
       "\n",
       "           min_sc       avg_sc       max_sc      std_sc  \n",
       "0      434.735910  1009.641142  2161.378419  416.130162  \n",
       "1      422.148634  1097.386582  2123.551926  451.090306  \n",
       "2      291.909819   991.248812  2980.423978  688.983759  \n",
       "3      369.349090  1044.968954  2045.723166  404.911227  \n",
       "4      395.814580  1026.078903  2352.828746  413.301996  \n",
       "...           ...          ...          ...         ...  \n",
       "11125  327.117005  1075.957907  2119.978221  489.302061  \n",
       "11126  334.493258   889.486936  2626.316454  469.690909  \n",
       "11127  566.711898  1066.883145  2340.979582  460.148163  \n",
       "11128  651.189324  1095.364001  1907.227408  411.637243  \n",
       "11129  406.277675  1022.974252  2009.081023  378.511378  \n",
       "\n",
       "[11130 rows x 17 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.drop('mfcc', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "87a4b17c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>min_rms</th>\n",
       "      <th>avg_rms</th>\n",
       "      <th>max_rms</th>\n",
       "      <th>std_rms</th>\n",
       "      <th>min_zrc</th>\n",
       "      <th>avg_zrc</th>\n",
       "      <th>max_zrc</th>\n",
       "      <th>std_zrc</th>\n",
       "      <th>min_sb</th>\n",
       "      <th>avg_sb</th>\n",
       "      <th>max_sb</th>\n",
       "      <th>std_sb</th>\n",
       "      <th>min_sc</th>\n",
       "      <th>avg_sc</th>\n",
       "      <th>max_sc</th>\n",
       "      <th>std_sc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001167</td>\n",
       "      <td>0.103407</td>\n",
       "      <td>0.189941</td>\n",
       "      <td>0.047770</td>\n",
       "      <td>0.067383</td>\n",
       "      <td>0.189209</td>\n",
       "      <td>0.440430</td>\n",
       "      <td>0.094806</td>\n",
       "      <td>394.431290</td>\n",
       "      <td>880.691752</td>\n",
       "      <td>1307.266225</td>\n",
       "      <td>245.430824</td>\n",
       "      <td>434.735910</td>\n",
       "      <td>1009.641142</td>\n",
       "      <td>2161.378419</td>\n",
       "      <td>416.130162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000801</td>\n",
       "      <td>0.058658</td>\n",
       "      <td>0.103927</td>\n",
       "      <td>0.031081</td>\n",
       "      <td>0.079102</td>\n",
       "      <td>0.212576</td>\n",
       "      <td>0.539062</td>\n",
       "      <td>0.115285</td>\n",
       "      <td>480.439854</td>\n",
       "      <td>870.267340</td>\n",
       "      <td>1122.283493</td>\n",
       "      <td>160.383675</td>\n",
       "      <td>422.148634</td>\n",
       "      <td>1097.386582</td>\n",
       "      <td>2123.551926</td>\n",
       "      <td>451.090306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000754</td>\n",
       "      <td>0.067203</td>\n",
       "      <td>0.109837</td>\n",
       "      <td>0.031252</td>\n",
       "      <td>0.047852</td>\n",
       "      <td>0.204605</td>\n",
       "      <td>0.706055</td>\n",
       "      <td>0.200368</td>\n",
       "      <td>448.441120</td>\n",
       "      <td>828.700336</td>\n",
       "      <td>1435.614128</td>\n",
       "      <td>246.024383</td>\n",
       "      <td>291.909819</td>\n",
       "      <td>991.248812</td>\n",
       "      <td>2980.423978</td>\n",
       "      <td>688.983759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001090</td>\n",
       "      <td>0.056282</td>\n",
       "      <td>0.122838</td>\n",
       "      <td>0.031935</td>\n",
       "      <td>0.056641</td>\n",
       "      <td>0.161513</td>\n",
       "      <td>0.534180</td>\n",
       "      <td>0.120783</td>\n",
       "      <td>436.448730</td>\n",
       "      <td>899.991063</td>\n",
       "      <td>1271.609599</td>\n",
       "      <td>213.625065</td>\n",
       "      <td>369.349090</td>\n",
       "      <td>1044.968954</td>\n",
       "      <td>2045.723166</td>\n",
       "      <td>404.911227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.005269</td>\n",
       "      <td>0.055942</td>\n",
       "      <td>0.114724</td>\n",
       "      <td>0.029470</td>\n",
       "      <td>0.044922</td>\n",
       "      <td>0.132704</td>\n",
       "      <td>0.386719</td>\n",
       "      <td>0.085825</td>\n",
       "      <td>547.596459</td>\n",
       "      <td>1014.481168</td>\n",
       "      <td>1391.435266</td>\n",
       "      <td>217.824753</td>\n",
       "      <td>395.814580</td>\n",
       "      <td>1026.078903</td>\n",
       "      <td>2352.828746</td>\n",
       "      <td>413.301996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11125</th>\n",
       "      <td>0.000496</td>\n",
       "      <td>0.051814</td>\n",
       "      <td>0.105858</td>\n",
       "      <td>0.028519</td>\n",
       "      <td>0.054688</td>\n",
       "      <td>0.196100</td>\n",
       "      <td>0.597656</td>\n",
       "      <td>0.134253</td>\n",
       "      <td>407.614581</td>\n",
       "      <td>888.767232</td>\n",
       "      <td>1286.562931</td>\n",
       "      <td>199.557633</td>\n",
       "      <td>327.117005</td>\n",
       "      <td>1075.957907</td>\n",
       "      <td>2119.978221</td>\n",
       "      <td>489.302061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11126</th>\n",
       "      <td>0.010991</td>\n",
       "      <td>0.076711</td>\n",
       "      <td>0.134443</td>\n",
       "      <td>0.036779</td>\n",
       "      <td>0.046875</td>\n",
       "      <td>0.142241</td>\n",
       "      <td>0.453125</td>\n",
       "      <td>0.105300</td>\n",
       "      <td>279.799074</td>\n",
       "      <td>837.773872</td>\n",
       "      <td>1161.597266</td>\n",
       "      <td>204.123944</td>\n",
       "      <td>334.493258</td>\n",
       "      <td>889.486936</td>\n",
       "      <td>2626.316454</td>\n",
       "      <td>469.690909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11127</th>\n",
       "      <td>0.006336</td>\n",
       "      <td>0.063076</td>\n",
       "      <td>0.114340</td>\n",
       "      <td>0.028879</td>\n",
       "      <td>0.035156</td>\n",
       "      <td>0.144206</td>\n",
       "      <td>0.616211</td>\n",
       "      <td>0.134536</td>\n",
       "      <td>715.505224</td>\n",
       "      <td>988.036607</td>\n",
       "      <td>1311.033228</td>\n",
       "      <td>145.070914</td>\n",
       "      <td>566.711898</td>\n",
       "      <td>1066.883145</td>\n",
       "      <td>2340.979582</td>\n",
       "      <td>460.148163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11128</th>\n",
       "      <td>0.005160</td>\n",
       "      <td>0.094933</td>\n",
       "      <td>0.188103</td>\n",
       "      <td>0.061273</td>\n",
       "      <td>0.073242</td>\n",
       "      <td>0.219238</td>\n",
       "      <td>0.410156</td>\n",
       "      <td>0.117426</td>\n",
       "      <td>471.818934</td>\n",
       "      <td>809.624811</td>\n",
       "      <td>1178.005456</td>\n",
       "      <td>214.518913</td>\n",
       "      <td>651.189324</td>\n",
       "      <td>1095.364001</td>\n",
       "      <td>1907.227408</td>\n",
       "      <td>411.637243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11129</th>\n",
       "      <td>0.000523</td>\n",
       "      <td>0.062909</td>\n",
       "      <td>0.127007</td>\n",
       "      <td>0.033762</td>\n",
       "      <td>0.060547</td>\n",
       "      <td>0.182408</td>\n",
       "      <td>0.486328</td>\n",
       "      <td>0.117248</td>\n",
       "      <td>465.102776</td>\n",
       "      <td>819.474318</td>\n",
       "      <td>1156.474441</td>\n",
       "      <td>165.770772</td>\n",
       "      <td>406.277675</td>\n",
       "      <td>1022.974252</td>\n",
       "      <td>2009.081023</td>\n",
       "      <td>378.511378</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11130 rows Ã— 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        min_rms   avg_rms   max_rms   std_rms   min_zrc   avg_zrc   max_zrc  \\\n",
       "0      0.001167  0.103407  0.189941  0.047770  0.067383  0.189209  0.440430   \n",
       "1      0.000801  0.058658  0.103927  0.031081  0.079102  0.212576  0.539062   \n",
       "2      0.000754  0.067203  0.109837  0.031252  0.047852  0.204605  0.706055   \n",
       "3      0.001090  0.056282  0.122838  0.031935  0.056641  0.161513  0.534180   \n",
       "4      0.005269  0.055942  0.114724  0.029470  0.044922  0.132704  0.386719   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "11125  0.000496  0.051814  0.105858  0.028519  0.054688  0.196100  0.597656   \n",
       "11126  0.010991  0.076711  0.134443  0.036779  0.046875  0.142241  0.453125   \n",
       "11127  0.006336  0.063076  0.114340  0.028879  0.035156  0.144206  0.616211   \n",
       "11128  0.005160  0.094933  0.188103  0.061273  0.073242  0.219238  0.410156   \n",
       "11129  0.000523  0.062909  0.127007  0.033762  0.060547  0.182408  0.486328   \n",
       "\n",
       "        std_zrc      min_sb       avg_sb       max_sb      std_sb      min_sc  \\\n",
       "0      0.094806  394.431290   880.691752  1307.266225  245.430824  434.735910   \n",
       "1      0.115285  480.439854   870.267340  1122.283493  160.383675  422.148634   \n",
       "2      0.200368  448.441120   828.700336  1435.614128  246.024383  291.909819   \n",
       "3      0.120783  436.448730   899.991063  1271.609599  213.625065  369.349090   \n",
       "4      0.085825  547.596459  1014.481168  1391.435266  217.824753  395.814580   \n",
       "...         ...         ...          ...          ...         ...         ...   \n",
       "11125  0.134253  407.614581   888.767232  1286.562931  199.557633  327.117005   \n",
       "11126  0.105300  279.799074   837.773872  1161.597266  204.123944  334.493258   \n",
       "11127  0.134536  715.505224   988.036607  1311.033228  145.070914  566.711898   \n",
       "11128  0.117426  471.818934   809.624811  1178.005456  214.518913  651.189324   \n",
       "11129  0.117248  465.102776   819.474318  1156.474441  165.770772  406.277675   \n",
       "\n",
       "            avg_sc       max_sc      std_sc  \n",
       "0      1009.641142  2161.378419  416.130162  \n",
       "1      1097.386582  2123.551926  451.090306  \n",
       "2       991.248812  2980.423978  688.983759  \n",
       "3      1044.968954  2045.723166  404.911227  \n",
       "4      1026.078903  2352.828746  413.301996  \n",
       "...            ...          ...         ...  \n",
       "11125  1075.957907  2119.978221  489.302061  \n",
       "11126   889.486936  2626.316454  469.690909  \n",
       "11127  1066.883145  2340.979582  460.148163  \n",
       "11128  1095.364001  1907.227408  411.637243  \n",
       "11129  1022.974252  2009.081023  378.511378  \n",
       "\n",
       "[11130 rows x 16 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = data.drop(['lable', 'mfcc'], axis=1)\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc32abbb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['american', 'american', 'american', ..., 'australian', 'american',\n",
       "       'indian'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lables = np.array(data['lable'])\n",
    "\n",
    "lables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e7f6f29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(features, lables, test_size = 0.25, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "73b28a95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8347, 16), (2783, 16), (8347,), (2783,))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.shape, test_features.shape, train_labels.shape, test_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dc13357b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           1.2866           0.0281           34.89s\n",
      "         2           1.2738           0.0289           34.85s\n",
      "         3           1.1909           0.0244           33.70s\n",
      "         4           1.1876           0.0227           32.53s\n",
      "         5           1.1689           0.0206           32.21s\n",
      "         6           1.1233           0.0185           31.57s\n",
      "         7           1.1385           0.0171           31.19s\n",
      "         8           1.1006           0.0160           31.49s\n",
      "         9           1.1084           0.0175           31.12s\n",
      "        10           1.0665           0.0172           30.76s\n",
      "        20           0.9401           0.0091           29.58s\n",
      "        30           0.8516           0.0050           28.88s\n",
      "        40           0.8048           0.0033           28.73s\n",
      "        50           0.7512           0.0026           28.30s\n",
      "        60           0.7249           0.0018           28.05s\n",
      "        70           0.7008           0.0016           27.84s\n",
      "        80           0.6702           0.0013           27.60s\n",
      "        90           0.6418           0.0008           27.38s\n",
      "       100           0.6230           0.0005           27.06s\n",
      "       200           0.4865           0.0002           24.14s\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "lr = 0.05\n",
      "0.7175709665828243\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    american       0.71      0.88      0.79      1439\n",
      "  australian       0.78      0.69      0.73       368\n",
      "     british       0.75      0.58      0.65       386\n",
      "      indian       0.71      0.41      0.52       400\n",
      "       welsh       0.58      0.43      0.49       190\n",
      "\n",
      "    accuracy                           0.72      2783\n",
      "   macro avg       0.71      0.60      0.64      2783\n",
      "weighted avg       0.72      0.72      0.70      2783\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           1.2239           0.0659           33.57s\n",
      "         2           1.1786           0.0481           32.03s\n",
      "         3           1.1306           0.0391           30.24s\n",
      "         4           1.1175           0.0315           29.65s\n",
      "         5           1.0691           0.0312           29.36s\n",
      "         6           1.0313           0.0247           29.32s\n",
      "         7           1.0047           0.0223           29.19s\n",
      "         8           0.9813           0.0212           29.77s\n",
      "         9           0.9658           0.0147           29.71s\n",
      "        10           0.9647           0.0178           29.59s\n",
      "        20           0.8145           0.0081           30.57s\n",
      "        30           0.7244           0.0026           33.74s\n",
      "        40           0.6612           0.0017           32.81s\n",
      "        50           0.6331           0.0003           31.76s\n",
      "        60           0.5964           0.0004           30.92s\n",
      "        70           0.5592          -0.0003           30.32s\n",
      "        80           0.5654          -0.0000           29.80s\n",
      "        90           0.5120           0.0001           29.72s\n",
      "       100           0.4911          -0.0001           29.56s\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "lr = 0.1\n",
      "0.7139777218828602\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    american       0.71      0.86      0.78      1439\n",
      "  australian       0.78      0.71      0.74       368\n",
      "     british       0.71      0.59      0.65       386\n",
      "      indian       0.68      0.43      0.53       400\n",
      "       welsh       0.62      0.43      0.51       190\n",
      "\n",
      "    accuracy                           0.71      2783\n",
      "   macro avg       0.70      0.61      0.64      2783\n",
      "weighted avg       0.71      0.71      0.70      2783\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           1.1414           0.1086           30.00s\n",
      "         2           1.0933           0.0787           29.97s\n",
      "         3           1.0180           0.0504           32.66s\n",
      "         4           0.9695           0.0434           32.87s\n",
      "         5           0.9339           0.0321           32.80s\n",
      "         6           0.8901           0.0264           32.57s\n",
      "         7           0.8853           0.0217           31.95s\n",
      "         8           0.8385           0.0168           31.73s\n",
      "         9           0.8340           0.0179           31.94s\n",
      "        10           0.7988           0.0112           31.65s\n",
      "        20           0.6701           0.0020           30.17s\n",
      "        30           0.6059      -26370.6499           29.52s\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "lr = 0.2\n",
      "0.6737333812432627\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    american       0.68      0.86      0.76      1439\n",
      "  australian       0.72      0.67      0.70       368\n",
      "     british       0.68      0.47      0.55       386\n",
      "      indian       0.63      0.34      0.44       400\n",
      "       welsh       0.57      0.41      0.47       190\n",
      "\n",
      "    accuracy                           0.67      2783\n",
      "   macro avg       0.66      0.55      0.58      2783\n",
      "weighted avg       0.67      0.67      0.66      2783\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           1.1182           0.1397           31.37s\n",
      "         2           1.0548           0.0650           30.69s\n",
      "         3           0.9926           0.0522           29.53s\n",
      "         4           0.9229           0.0457           30.33s\n",
      "         5           0.9215           0.0297           31.47s\n",
      "         6           0.8521           0.0203           30.85s\n",
      "         7           0.8422           0.0184           30.64s\n",
      "         8           0.8286           0.0164           31.24s\n",
      "         9           0.7803           0.0171           31.44s\n",
      "        10           0.7714           0.0100           31.23s\n",
      "        20           0.6480          -0.0008           30.21s\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "lr = 0.25\n",
      "0.6823571685231764\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    american       0.69      0.85      0.76      1439\n",
      "  australian       0.75      0.66      0.70       368\n",
      "     british       0.67      0.49      0.57       386\n",
      "      indian       0.64      0.41      0.50       400\n",
      "       welsh       0.54      0.38      0.44       190\n",
      "\n",
      "    accuracy                           0.68      2783\n",
      "   macro avg       0.66      0.56      0.59      2783\n",
      "weighted avg       0.68      0.68      0.67      2783\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           1.0927           0.1538           35.26s\n",
      "         2           1.0077           0.0818           36.05s\n",
      "         3           0.9549           0.0513           37.66s\n",
      "         4           0.9032           0.0447           38.56s\n",
      "         5           0.8587           0.0326           37.68s\n",
      "         6           0.7972           0.0141           37.58s\n",
      "         7           0.7966           0.0165           37.11s\n",
      "         8           0.7905           0.0103           37.09s\n",
      "         9           0.7629          -0.0034           37.38s\n",
      "        10           0.7548           0.0071           37.08s\n",
      "        20           0.6682          -0.0078           33.42s\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "lr = 0.3\n",
      "0.6629536471433705\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    american       0.68      0.85      0.75      1439\n",
      "  australian       0.72      0.65      0.69       368\n",
      "     british       0.65      0.47      0.55       386\n",
      "      indian       0.60      0.36      0.45       400\n",
      "       welsh       0.46      0.32      0.38       190\n",
      "\n",
      "    accuracy                           0.66      2783\n",
      "   macro avg       0.62      0.53      0.56      2783\n",
      "weighted avg       0.65      0.66      0.65      2783\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           1.0374           0.1708           30.73s\n",
      "         2           0.9468           0.0945           29.63s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         3           0.9075           0.0403           30.09s\n",
      "         4           0.8379           0.0351           30.61s\n",
      "         5           0.8133          -0.9064           29.90s\n",
      "         6           1.0714          -0.9617           29.77s\n",
      "         7           1.7035           0.0085           29.87s\n",
      "         8           2.1656           0.0073           30.20s\n",
      "         9           1.9420           0.0129           30.08s\n",
      "        10           1.3032          -0.0001           30.24s\n",
      "        20   436925596.7891 -34688018388.2120           30.09s\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "lr = 0.4\n",
      "0.6521739130434783\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    american       0.68      0.81      0.74      1439\n",
      "  australian       0.70      0.66      0.68       368\n",
      "     british       0.60      0.46      0.52       386\n",
      "      indian       0.58      0.40      0.48       400\n",
      "       welsh       0.47      0.34      0.39       190\n",
      "\n",
      "    accuracy                           0.65      2783\n",
      "   macro avg       0.61      0.53      0.56      2783\n",
      "weighted avg       0.64      0.65      0.64      2783\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           1.0010           0.2060           35.34s\n",
      "         2           0.9382           0.0630           37.32s\n",
      "         3           0.8565           0.0434           38.20s\n",
      "         4           0.8607           0.0295           36.93s\n",
      "         5           0.7727           0.0049           36.12s\n",
      "         6           0.7926          -0.0263           35.46s\n",
      "         7           0.7951          -0.0437           34.42s\n",
      "         8           3.1397          -3.2809           33.70s\n",
      "         9           9.6660          -0.0200           33.25s\n",
      "        10           5.7847          -0.0342           33.72s\n",
      "        20 6396590682546.8652     -880216.2061           31.64s\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "lr = 0.5\n",
      "0.6525332375134747\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    american       0.69      0.80      0.74      1439\n",
      "  australian       0.73      0.64      0.68       368\n",
      "     british       0.56      0.49      0.53       386\n",
      "      indian       0.57      0.39      0.46       400\n",
      "       welsh       0.48      0.43      0.45       190\n",
      "\n",
      "    accuracy                           0.65      2783\n",
      "   macro avg       0.61      0.55      0.57      2783\n",
      "weighted avg       0.64      0.65      0.64      2783\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "lr_list = [0.05, 0.1, 0.2, 0.25, 0.3, 0.4, 0.5]\n",
    "for lr in lr_list:\n",
    "    model_gbm = GradientBoostingClassifier(n_estimators=1000,\n",
    "                                           learning_rate=lr,\n",
    "                                           max_depth=4,\n",
    "                                           subsample=0.3,\n",
    "                                           validation_fraction=0.1,\n",
    "                                           n_iter_no_change=20,\n",
    "                                           max_features='log2',\n",
    "                                           verbose=1)\n",
    "    model_gbm.fit(train_features, train_labels)\n",
    "    print('---------------------------------------------------------------------------------------------------------')\n",
    "    print('lr =', lr)\n",
    "    print(model_gbm.score(test_features, test_labels))\n",
    "    print('---------------------------------------------------------------------------------------------------------')\n",
    "    print(classification_report(test_labels,model_gbm.predict(test_features)))\n",
    "    print('---------------------------------------------------------------------------------------------------------')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b4ea317f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1155   61   97   84   42]\n",
      " [ 110  235   13    3    7]\n",
      " [ 142   21  191   15   17]\n",
      " [ 195    3   25  154   23]\n",
      " [  79    2   14   14   81]]\n"
     ]
    }
   ],
   "source": [
    "conf_mat = confusion_matrix(test_labels,model_gbm.predict(test_features))\n",
    "print(conf_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d2dfa387",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'plotly'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mplotly\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfigure_factory\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mff\u001b[39;00m\n\u001b[1;32m      2\u001b[0m acc \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# set up figure \u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'plotly'"
     ]
    }
   ],
   "source": [
    "import plotly.figure_factory as ff\n",
    "acc = []\n",
    "# set up figure \n",
    "fig = ff.create_annotated_heatmap(z, x=x, y=y, annotation_text=z_text, colorscale='Viridis')\n",
    "\n",
    "# add title\n",
    "fig.update_layout(title_text='<i><b>Confusion matrix</b></i>',\n",
    "                  #xaxis = dict(title='x'),\n",
    "                  #yaxis = dict(title='x')\n",
    "                 )\n",
    "\n",
    "# add custom xaxis title\n",
    "fig.add_annotation(dict(font=dict(color=\"black\",size=14),\n",
    "                        x=0.5,\n",
    "                        y=-0.15,\n",
    "                        showarrow=False,\n",
    "                        text=\"Predicted value\",\n",
    "                        xref=\"paper\",\n",
    "                        yref=\"paper\"))\n",
    "\n",
    "# add custom yaxis title\n",
    "fig.add_annotation(dict(font=dict(color=\"black\",size=14),\n",
    "                        x=-0.35,\n",
    "                        y=0.5,\n",
    "                        showarrow=False,\n",
    "                        text=\"Real value\",\n",
    "                        textangle=-90,\n",
    "                        xref=\"paper\",\n",
    "                        yref=\"paper\"))\n",
    "\n",
    "# adjust margins to make room for yaxis title\n",
    "fig.update_layout(margin=dict(t=50, l=200))\n",
    "\n",
    "# add colorbar\n",
    "fig['data'][0]['showscale'] = True\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1574e176",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
