{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f1f68c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "110438f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import IPython.display as ipd\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import random\n",
    "import pandas as pd\n",
    "from statistics import mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "058d4080",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_json('../4_accent_features_22k.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a24526a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lable</th>\n",
       "      <th>rms</th>\n",
       "      <th>zrc</th>\n",
       "      <th>sb</th>\n",
       "      <th>sc</th>\n",
       "      <th>mfcc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bangla</td>\n",
       "      <td>[0.0013946438000000002, 0.0020170733, 0.001862...</td>\n",
       "      <td>[0.0380859375, 0.083984375, 0.109375, 0.112304...</td>\n",
       "      <td>[2886.401524858, 2796.0275535111, 2909.4122465...</td>\n",
       "      <td>[2388.1567998945, 2180.9140804113, 2443.847420...</td>\n",
       "      <td>[[-471.7465515137, -456.7153930664, -459.34436...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>malayalam</td>\n",
       "      <td>[0.0018541168000000001, 0.0027880995, 0.002781...</td>\n",
       "      <td>[0.0302734375, 0.0654296875, 0.078125, 0.08007...</td>\n",
       "      <td>[2678.5589162968, 2631.4120034514, 2610.859365...</td>\n",
       "      <td>[1946.2487991002, 2028.1892441629, 2041.918837...</td>\n",
       "      <td>[[-472.3463745117, -446.223815918, -440.630249...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>malayalam</td>\n",
       "      <td>[0.0020720728, 0.002927064, 0.0027094684, 0.00...</td>\n",
       "      <td>[0.0419921875, 0.078125, 0.0654296875, 0.08300...</td>\n",
       "      <td>[2891.4828893877, 2809.1249499908, 2620.486954...</td>\n",
       "      <td>[2412.3271069461, 2277.5214977171, 1993.719309...</td>\n",
       "      <td>[[-476.6443786621, -446.4409484863, -445.25283...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>odiya</td>\n",
       "      <td>[0.0016051014, 0.0025093982, 0.002824514200000...</td>\n",
       "      <td>[0.0400390625, 0.072265625, 0.0615234375, 0.07...</td>\n",
       "      <td>[2697.6979899722, 2628.8437120369, 2626.839185...</td>\n",
       "      <td>[2141.7725273933, 2088.7253072531, 2009.974668...</td>\n",
       "      <td>[[-477.852935791, -448.7857971191, -444.822631...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bangla</td>\n",
       "      <td>[0.0019763573, 0.0027296843, 0.003020898200000...</td>\n",
       "      <td>[0.0400390625, 0.0771484375, 0.0791015625, 0.0...</td>\n",
       "      <td>[2468.2086847496, 2488.7754963086, 2448.232229...</td>\n",
       "      <td>[1936.6119578417, 2079.1606236968, 1945.780888...</td>\n",
       "      <td>[[-446.6452941895, -422.6954345703, -426.02734...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6178</th>\n",
       "      <td>telugu</td>\n",
       "      <td>[0.0013207975, 0.0019568782, 0.002198813, 0.03...</td>\n",
       "      <td>[0.0400390625, 0.0810546875, 0.078125, 0.06542...</td>\n",
       "      <td>[2781.7079534371, 2721.4191785234, 2722.215196...</td>\n",
       "      <td>[2389.1352454214, 2151.9468806418, 2232.123016...</td>\n",
       "      <td>[[-494.7901000977, -458.7627563477, -429.15322...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6179</th>\n",
       "      <td>odiya</td>\n",
       "      <td>[0.0017946149, 0.0026038224, 0.0033023616, 0.0...</td>\n",
       "      <td>[0.0546875, 0.1015625, 0.076171875, 0.06347656...</td>\n",
       "      <td>[2817.6374684681, 2590.470282003, 2535.3186567...</td>\n",
       "      <td>[2697.3529675747, 2111.9722581644, 1928.624935...</td>\n",
       "      <td>[[-471.3420715332, -423.157043457, -421.175170...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6180</th>\n",
       "      <td>malayalam</td>\n",
       "      <td>[0.0017542240000000002, 0.0025207074, 0.002529...</td>\n",
       "      <td>[0.033203125, 0.05859375, 0.0498046875, 0.0722...</td>\n",
       "      <td>[2792.8350576795, 2739.9685261638, 2786.457334...</td>\n",
       "      <td>[2366.7544940406, 2108.1867222711, 2258.360337...</td>\n",
       "      <td>[[-488.4339599609, -459.7818603516, -461.59078...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6181</th>\n",
       "      <td>bangla</td>\n",
       "      <td>[0.0014164349000000001, 0.0019143918000000002,...</td>\n",
       "      <td>[0.0390625, 0.09375000000000001, 0.1005859375,...</td>\n",
       "      <td>[2767.9994245806, 2828.1800438228, 2766.121219...</td>\n",
       "      <td>[2193.7947199968, 2402.7724275448, 2370.159846...</td>\n",
       "      <td>[[-490.4011535645, -462.4995422363, -463.83020...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6182</th>\n",
       "      <td>telugu</td>\n",
       "      <td>[0.0484213158, 0.06314402820000001, 0.05158800...</td>\n",
       "      <td>[0.009765625, 0.015625, 0.015625, 0.03125, 0.0...</td>\n",
       "      <td>[1486.085447337, 1078.1197341638, 1242.7112051...</td>\n",
       "      <td>[713.7242808265, 461.0879906932, 511.009573229...</td>\n",
       "      <td>[[-332.3883056641, -366.9843444824, -323.56549...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6183 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          lable                                                rms  \\\n",
       "0        bangla  [0.0013946438000000002, 0.0020170733, 0.001862...   \n",
       "1     malayalam  [0.0018541168000000001, 0.0027880995, 0.002781...   \n",
       "2     malayalam  [0.0020720728, 0.002927064, 0.0027094684, 0.00...   \n",
       "3         odiya  [0.0016051014, 0.0025093982, 0.002824514200000...   \n",
       "4        bangla  [0.0019763573, 0.0027296843, 0.003020898200000...   \n",
       "...         ...                                                ...   \n",
       "6178     telugu  [0.0013207975, 0.0019568782, 0.002198813, 0.03...   \n",
       "6179      odiya  [0.0017946149, 0.0026038224, 0.0033023616, 0.0...   \n",
       "6180  malayalam  [0.0017542240000000002, 0.0025207074, 0.002529...   \n",
       "6181     bangla  [0.0014164349000000001, 0.0019143918000000002,...   \n",
       "6182     telugu  [0.0484213158, 0.06314402820000001, 0.05158800...   \n",
       "\n",
       "                                                    zrc  \\\n",
       "0     [0.0380859375, 0.083984375, 0.109375, 0.112304...   \n",
       "1     [0.0302734375, 0.0654296875, 0.078125, 0.08007...   \n",
       "2     [0.0419921875, 0.078125, 0.0654296875, 0.08300...   \n",
       "3     [0.0400390625, 0.072265625, 0.0615234375, 0.07...   \n",
       "4     [0.0400390625, 0.0771484375, 0.0791015625, 0.0...   \n",
       "...                                                 ...   \n",
       "6178  [0.0400390625, 0.0810546875, 0.078125, 0.06542...   \n",
       "6179  [0.0546875, 0.1015625, 0.076171875, 0.06347656...   \n",
       "6180  [0.033203125, 0.05859375, 0.0498046875, 0.0722...   \n",
       "6181  [0.0390625, 0.09375000000000001, 0.1005859375,...   \n",
       "6182  [0.009765625, 0.015625, 0.015625, 0.03125, 0.0...   \n",
       "\n",
       "                                                     sb  \\\n",
       "0     [2886.401524858, 2796.0275535111, 2909.4122465...   \n",
       "1     [2678.5589162968, 2631.4120034514, 2610.859365...   \n",
       "2     [2891.4828893877, 2809.1249499908, 2620.486954...   \n",
       "3     [2697.6979899722, 2628.8437120369, 2626.839185...   \n",
       "4     [2468.2086847496, 2488.7754963086, 2448.232229...   \n",
       "...                                                 ...   \n",
       "6178  [2781.7079534371, 2721.4191785234, 2722.215196...   \n",
       "6179  [2817.6374684681, 2590.470282003, 2535.3186567...   \n",
       "6180  [2792.8350576795, 2739.9685261638, 2786.457334...   \n",
       "6181  [2767.9994245806, 2828.1800438228, 2766.121219...   \n",
       "6182  [1486.085447337, 1078.1197341638, 1242.7112051...   \n",
       "\n",
       "                                                     sc  \\\n",
       "0     [2388.1567998945, 2180.9140804113, 2443.847420...   \n",
       "1     [1946.2487991002, 2028.1892441629, 2041.918837...   \n",
       "2     [2412.3271069461, 2277.5214977171, 1993.719309...   \n",
       "3     [2141.7725273933, 2088.7253072531, 2009.974668...   \n",
       "4     [1936.6119578417, 2079.1606236968, 1945.780888...   \n",
       "...                                                 ...   \n",
       "6178  [2389.1352454214, 2151.9468806418, 2232.123016...   \n",
       "6179  [2697.3529675747, 2111.9722581644, 1928.624935...   \n",
       "6180  [2366.7544940406, 2108.1867222711, 2258.360337...   \n",
       "6181  [2193.7947199968, 2402.7724275448, 2370.159846...   \n",
       "6182  [713.7242808265, 461.0879906932, 511.009573229...   \n",
       "\n",
       "                                                   mfcc  \n",
       "0     [[-471.7465515137, -456.7153930664, -459.34436...  \n",
       "1     [[-472.3463745117, -446.223815918, -440.630249...  \n",
       "2     [[-476.6443786621, -446.4409484863, -445.25283...  \n",
       "3     [[-477.852935791, -448.7857971191, -444.822631...  \n",
       "4     [[-446.6452941895, -422.6954345703, -426.02734...  \n",
       "...                                                 ...  \n",
       "6178  [[-494.7901000977, -458.7627563477, -429.15322...  \n",
       "6179  [[-471.3420715332, -423.157043457, -421.175170...  \n",
       "6180  [[-488.4339599609, -459.7818603516, -461.59078...  \n",
       "6181  [[-490.4011535645, -462.4995422363, -463.83020...  \n",
       "6182  [[-332.3883056641, -366.9843444824, -323.56549...  \n",
       "\n",
       "[6183 rows x 6 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fbd1f5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_min_avg_max(column, data=data):\n",
    "    row_data_min, row_data_avg, row_data_max = [], [], []\n",
    "    for row in data[column]:\n",
    "        row_data_min.append(min(row))\n",
    "        row_data_avg.append(mean(row))\n",
    "        row_data_max.append(max(row))\n",
    "    \n",
    "    data.drop(column, axis=1, inplace=True)\n",
    "    data[f'min_{column}'] = row_data_min\n",
    "    data[f'avg_{column}'] = row_data_avg\n",
    "    data[f'max_{column}'] = row_data_max\n",
    "    \n",
    "    return row_data_min, row_data_avg, row_data_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "08903337",
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b,c = get_min_avg_max('rms')\n",
    "a,b,c = get_min_avg_max('zrc')\n",
    "a,b,c = get_min_avg_max('sb')\n",
    "a,b,c = get_min_avg_max('sc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4eb85588",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lable</th>\n",
       "      <th>min_rms</th>\n",
       "      <th>avg_rms</th>\n",
       "      <th>max_rms</th>\n",
       "      <th>min_zrc</th>\n",
       "      <th>avg_zrc</th>\n",
       "      <th>max_zrc</th>\n",
       "      <th>min_sb</th>\n",
       "      <th>avg_sb</th>\n",
       "      <th>max_sb</th>\n",
       "      <th>min_sc</th>\n",
       "      <th>avg_sc</th>\n",
       "      <th>max_sc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bangla</td>\n",
       "      <td>0.001395</td>\n",
       "      <td>0.086223</td>\n",
       "      <td>0.292426</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.154839</td>\n",
       "      <td>0.728516</td>\n",
       "      <td>690.435133</td>\n",
       "      <td>2202.139263</td>\n",
       "      <td>3778.894295</td>\n",
       "      <td>450.437122</td>\n",
       "      <td>2555.452742</td>\n",
       "      <td>7573.473501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>malayalam</td>\n",
       "      <td>0.001854</td>\n",
       "      <td>0.051283</td>\n",
       "      <td>0.201747</td>\n",
       "      <td>0.017578</td>\n",
       "      <td>0.100883</td>\n",
       "      <td>0.664062</td>\n",
       "      <td>840.251371</td>\n",
       "      <td>2266.859190</td>\n",
       "      <td>3728.589663</td>\n",
       "      <td>512.745162</td>\n",
       "      <td>2078.347464</td>\n",
       "      <td>7123.439391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>malayalam</td>\n",
       "      <td>0.001721</td>\n",
       "      <td>0.020130</td>\n",
       "      <td>0.136092</td>\n",
       "      <td>0.016602</td>\n",
       "      <td>0.114834</td>\n",
       "      <td>0.635742</td>\n",
       "      <td>1225.640372</td>\n",
       "      <td>2397.933800</td>\n",
       "      <td>3083.726345</td>\n",
       "      <td>585.840174</td>\n",
       "      <td>2287.418665</td>\n",
       "      <td>7209.135808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>odiya</td>\n",
       "      <td>0.001605</td>\n",
       "      <td>0.014365</td>\n",
       "      <td>0.085764</td>\n",
       "      <td>0.016602</td>\n",
       "      <td>0.072445</td>\n",
       "      <td>0.332031</td>\n",
       "      <td>1065.024228</td>\n",
       "      <td>2327.249148</td>\n",
       "      <td>3061.177303</td>\n",
       "      <td>551.961391</td>\n",
       "      <td>1844.255336</td>\n",
       "      <td>4871.640815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bangla</td>\n",
       "      <td>0.001976</td>\n",
       "      <td>0.052965</td>\n",
       "      <td>0.204123</td>\n",
       "      <td>0.016602</td>\n",
       "      <td>0.080566</td>\n",
       "      <td>0.602539</td>\n",
       "      <td>706.835106</td>\n",
       "      <td>2042.273991</td>\n",
       "      <td>3649.956346</td>\n",
       "      <td>447.082234</td>\n",
       "      <td>1774.222759</td>\n",
       "      <td>7000.516471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6178</th>\n",
       "      <td>telugu</td>\n",
       "      <td>0.001321</td>\n",
       "      <td>0.046776</td>\n",
       "      <td>0.136986</td>\n",
       "      <td>0.009766</td>\n",
       "      <td>0.059961</td>\n",
       "      <td>0.504883</td>\n",
       "      <td>875.196785</td>\n",
       "      <td>1888.312374</td>\n",
       "      <td>2896.844442</td>\n",
       "      <td>441.360981</td>\n",
       "      <td>1468.854314</td>\n",
       "      <td>5380.341401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6179</th>\n",
       "      <td>odiya</td>\n",
       "      <td>0.001795</td>\n",
       "      <td>0.019663</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.082088</td>\n",
       "      <td>0.425781</td>\n",
       "      <td>1175.091343</td>\n",
       "      <td>2320.185029</td>\n",
       "      <td>3639.743682</td>\n",
       "      <td>574.554555</td>\n",
       "      <td>1934.522800</td>\n",
       "      <td>5186.208055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6180</th>\n",
       "      <td>malayalam</td>\n",
       "      <td>0.001380</td>\n",
       "      <td>0.030098</td>\n",
       "      <td>0.170651</td>\n",
       "      <td>0.013672</td>\n",
       "      <td>0.085098</td>\n",
       "      <td>0.390625</td>\n",
       "      <td>779.022654</td>\n",
       "      <td>2310.245655</td>\n",
       "      <td>3255.817300</td>\n",
       "      <td>511.193899</td>\n",
       "      <td>2015.218670</td>\n",
       "      <td>4854.653620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6181</th>\n",
       "      <td>bangla</td>\n",
       "      <td>0.001398</td>\n",
       "      <td>0.057666</td>\n",
       "      <td>0.224636</td>\n",
       "      <td>0.017578</td>\n",
       "      <td>0.122231</td>\n",
       "      <td>0.790039</td>\n",
       "      <td>703.419893</td>\n",
       "      <td>2305.310919</td>\n",
       "      <td>3807.206322</td>\n",
       "      <td>456.136777</td>\n",
       "      <td>2289.051523</td>\n",
       "      <td>7645.426565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6182</th>\n",
       "      <td>telugu</td>\n",
       "      <td>0.001465</td>\n",
       "      <td>0.047487</td>\n",
       "      <td>0.239017</td>\n",
       "      <td>0.009766</td>\n",
       "      <td>0.068735</td>\n",
       "      <td>0.240234</td>\n",
       "      <td>741.533559</td>\n",
       "      <td>2210.645469</td>\n",
       "      <td>3123.318353</td>\n",
       "      <td>452.790201</td>\n",
       "      <td>1738.376381</td>\n",
       "      <td>3814.649679</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6183 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          lable   min_rms   avg_rms   max_rms   min_zrc   avg_zrc   max_zrc  \\\n",
       "0        bangla  0.001395  0.086223  0.292426  0.015625  0.154839  0.728516   \n",
       "1     malayalam  0.001854  0.051283  0.201747  0.017578  0.100883  0.664062   \n",
       "2     malayalam  0.001721  0.020130  0.136092  0.016602  0.114834  0.635742   \n",
       "3         odiya  0.001605  0.014365  0.085764  0.016602  0.072445  0.332031   \n",
       "4        bangla  0.001976  0.052965  0.204123  0.016602  0.080566  0.602539   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "6178     telugu  0.001321  0.046776  0.136986  0.009766  0.059961  0.504883   \n",
       "6179      odiya  0.001795  0.019663  0.090794  0.015625  0.082088  0.425781   \n",
       "6180  malayalam  0.001380  0.030098  0.170651  0.013672  0.085098  0.390625   \n",
       "6181     bangla  0.001398  0.057666  0.224636  0.017578  0.122231  0.790039   \n",
       "6182     telugu  0.001465  0.047487  0.239017  0.009766  0.068735  0.240234   \n",
       "\n",
       "           min_sb       avg_sb       max_sb      min_sc       avg_sc  \\\n",
       "0      690.435133  2202.139263  3778.894295  450.437122  2555.452742   \n",
       "1      840.251371  2266.859190  3728.589663  512.745162  2078.347464   \n",
       "2     1225.640372  2397.933800  3083.726345  585.840174  2287.418665   \n",
       "3     1065.024228  2327.249148  3061.177303  551.961391  1844.255336   \n",
       "4      706.835106  2042.273991  3649.956346  447.082234  1774.222759   \n",
       "...           ...          ...          ...         ...          ...   \n",
       "6178   875.196785  1888.312374  2896.844442  441.360981  1468.854314   \n",
       "6179  1175.091343  2320.185029  3639.743682  574.554555  1934.522800   \n",
       "6180   779.022654  2310.245655  3255.817300  511.193899  2015.218670   \n",
       "6181   703.419893  2305.310919  3807.206322  456.136777  2289.051523   \n",
       "6182   741.533559  2210.645469  3123.318353  452.790201  1738.376381   \n",
       "\n",
       "           max_sc  \n",
       "0     7573.473501  \n",
       "1     7123.439391  \n",
       "2     7209.135808  \n",
       "3     4871.640815  \n",
       "4     7000.516471  \n",
       "...           ...  \n",
       "6178  5380.341401  \n",
       "6179  5186.208055  \n",
       "6180  4854.653620  \n",
       "6181  7645.426565  \n",
       "6182  3814.649679  \n",
       "\n",
       "[6183 rows x 13 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.drop('mfcc', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "87a4b17c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>min_rms</th>\n",
       "      <th>avg_rms</th>\n",
       "      <th>max_rms</th>\n",
       "      <th>min_zrc</th>\n",
       "      <th>avg_zrc</th>\n",
       "      <th>max_zrc</th>\n",
       "      <th>min_sb</th>\n",
       "      <th>avg_sb</th>\n",
       "      <th>max_sb</th>\n",
       "      <th>min_sc</th>\n",
       "      <th>avg_sc</th>\n",
       "      <th>max_sc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001395</td>\n",
       "      <td>0.086223</td>\n",
       "      <td>0.292426</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.154839</td>\n",
       "      <td>0.728516</td>\n",
       "      <td>690.435133</td>\n",
       "      <td>2202.139263</td>\n",
       "      <td>3778.894295</td>\n",
       "      <td>450.437122</td>\n",
       "      <td>2555.452742</td>\n",
       "      <td>7573.473501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001854</td>\n",
       "      <td>0.051283</td>\n",
       "      <td>0.201747</td>\n",
       "      <td>0.017578</td>\n",
       "      <td>0.100883</td>\n",
       "      <td>0.664062</td>\n",
       "      <td>840.251371</td>\n",
       "      <td>2266.859190</td>\n",
       "      <td>3728.589663</td>\n",
       "      <td>512.745162</td>\n",
       "      <td>2078.347464</td>\n",
       "      <td>7123.439391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001721</td>\n",
       "      <td>0.020130</td>\n",
       "      <td>0.136092</td>\n",
       "      <td>0.016602</td>\n",
       "      <td>0.114834</td>\n",
       "      <td>0.635742</td>\n",
       "      <td>1225.640372</td>\n",
       "      <td>2397.933800</td>\n",
       "      <td>3083.726345</td>\n",
       "      <td>585.840174</td>\n",
       "      <td>2287.418665</td>\n",
       "      <td>7209.135808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001605</td>\n",
       "      <td>0.014365</td>\n",
       "      <td>0.085764</td>\n",
       "      <td>0.016602</td>\n",
       "      <td>0.072445</td>\n",
       "      <td>0.332031</td>\n",
       "      <td>1065.024228</td>\n",
       "      <td>2327.249148</td>\n",
       "      <td>3061.177303</td>\n",
       "      <td>551.961391</td>\n",
       "      <td>1844.255336</td>\n",
       "      <td>4871.640815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001976</td>\n",
       "      <td>0.052965</td>\n",
       "      <td>0.204123</td>\n",
       "      <td>0.016602</td>\n",
       "      <td>0.080566</td>\n",
       "      <td>0.602539</td>\n",
       "      <td>706.835106</td>\n",
       "      <td>2042.273991</td>\n",
       "      <td>3649.956346</td>\n",
       "      <td>447.082234</td>\n",
       "      <td>1774.222759</td>\n",
       "      <td>7000.516471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6178</th>\n",
       "      <td>0.001321</td>\n",
       "      <td>0.046776</td>\n",
       "      <td>0.136986</td>\n",
       "      <td>0.009766</td>\n",
       "      <td>0.059961</td>\n",
       "      <td>0.504883</td>\n",
       "      <td>875.196785</td>\n",
       "      <td>1888.312374</td>\n",
       "      <td>2896.844442</td>\n",
       "      <td>441.360981</td>\n",
       "      <td>1468.854314</td>\n",
       "      <td>5380.341401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6179</th>\n",
       "      <td>0.001795</td>\n",
       "      <td>0.019663</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.082088</td>\n",
       "      <td>0.425781</td>\n",
       "      <td>1175.091343</td>\n",
       "      <td>2320.185029</td>\n",
       "      <td>3639.743682</td>\n",
       "      <td>574.554555</td>\n",
       "      <td>1934.522800</td>\n",
       "      <td>5186.208055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6180</th>\n",
       "      <td>0.001380</td>\n",
       "      <td>0.030098</td>\n",
       "      <td>0.170651</td>\n",
       "      <td>0.013672</td>\n",
       "      <td>0.085098</td>\n",
       "      <td>0.390625</td>\n",
       "      <td>779.022654</td>\n",
       "      <td>2310.245655</td>\n",
       "      <td>3255.817300</td>\n",
       "      <td>511.193899</td>\n",
       "      <td>2015.218670</td>\n",
       "      <td>4854.653620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6181</th>\n",
       "      <td>0.001398</td>\n",
       "      <td>0.057666</td>\n",
       "      <td>0.224636</td>\n",
       "      <td>0.017578</td>\n",
       "      <td>0.122231</td>\n",
       "      <td>0.790039</td>\n",
       "      <td>703.419893</td>\n",
       "      <td>2305.310919</td>\n",
       "      <td>3807.206322</td>\n",
       "      <td>456.136777</td>\n",
       "      <td>2289.051523</td>\n",
       "      <td>7645.426565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6182</th>\n",
       "      <td>0.001465</td>\n",
       "      <td>0.047487</td>\n",
       "      <td>0.239017</td>\n",
       "      <td>0.009766</td>\n",
       "      <td>0.068735</td>\n",
       "      <td>0.240234</td>\n",
       "      <td>741.533559</td>\n",
       "      <td>2210.645469</td>\n",
       "      <td>3123.318353</td>\n",
       "      <td>452.790201</td>\n",
       "      <td>1738.376381</td>\n",
       "      <td>3814.649679</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6183 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       min_rms   avg_rms   max_rms   min_zrc   avg_zrc   max_zrc       min_sb  \\\n",
       "0     0.001395  0.086223  0.292426  0.015625  0.154839  0.728516   690.435133   \n",
       "1     0.001854  0.051283  0.201747  0.017578  0.100883  0.664062   840.251371   \n",
       "2     0.001721  0.020130  0.136092  0.016602  0.114834  0.635742  1225.640372   \n",
       "3     0.001605  0.014365  0.085764  0.016602  0.072445  0.332031  1065.024228   \n",
       "4     0.001976  0.052965  0.204123  0.016602  0.080566  0.602539   706.835106   \n",
       "...        ...       ...       ...       ...       ...       ...          ...   \n",
       "6178  0.001321  0.046776  0.136986  0.009766  0.059961  0.504883   875.196785   \n",
       "6179  0.001795  0.019663  0.090794  0.015625  0.082088  0.425781  1175.091343   \n",
       "6180  0.001380  0.030098  0.170651  0.013672  0.085098  0.390625   779.022654   \n",
       "6181  0.001398  0.057666  0.224636  0.017578  0.122231  0.790039   703.419893   \n",
       "6182  0.001465  0.047487  0.239017  0.009766  0.068735  0.240234   741.533559   \n",
       "\n",
       "           avg_sb       max_sb      min_sc       avg_sc       max_sc  \n",
       "0     2202.139263  3778.894295  450.437122  2555.452742  7573.473501  \n",
       "1     2266.859190  3728.589663  512.745162  2078.347464  7123.439391  \n",
       "2     2397.933800  3083.726345  585.840174  2287.418665  7209.135808  \n",
       "3     2327.249148  3061.177303  551.961391  1844.255336  4871.640815  \n",
       "4     2042.273991  3649.956346  447.082234  1774.222759  7000.516471  \n",
       "...           ...          ...         ...          ...          ...  \n",
       "6178  1888.312374  2896.844442  441.360981  1468.854314  5380.341401  \n",
       "6179  2320.185029  3639.743682  574.554555  1934.522800  5186.208055  \n",
       "6180  2310.245655  3255.817300  511.193899  2015.218670  4854.653620  \n",
       "6181  2305.310919  3807.206322  456.136777  2289.051523  7645.426565  \n",
       "6182  2210.645469  3123.318353  452.790201  1738.376381  3814.649679  \n",
       "\n",
       "[6183 rows x 12 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = data.drop(['lable', 'mfcc'], axis=1)\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc32abbb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['bangla', 'malayalam', 'malayalam', ..., 'malayalam', 'bangla',\n",
       "       'telugu'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lables = np.array(data['lable'])\n",
    "\n",
    "lables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e7f6f29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(features, lables, test_size = 0.25, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "73b28a95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4637, 12), (1546, 12), (4637,), (1546,))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.shape, test_features.shape, train_labels.shape, test_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dc13357b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           1.2212           0.0795            1.15m\n",
      "         2           1.1364           0.0713           55.45s\n",
      "         3           1.0910           0.0660           50.50s\n",
      "         4           1.0339           0.0533           48.61s\n",
      "         5           0.9711           0.0486           49.20s\n",
      "         6           0.9292           0.0449           47.94s\n",
      "         7           0.8838           0.0362           47.17s\n",
      "         8           0.8543           0.0365           45.85s\n",
      "         9           0.8205           0.0337           44.80s\n",
      "        10           0.7856           0.0334           44.06s\n",
      "        20           0.5478           0.0150           41.85s\n",
      "        30           0.4226           0.0084           40.76s\n",
      "        40           0.3649           0.0053           39.36s\n",
      "        50           0.2953           0.0035           38.30s\n",
      "        60           0.2584           0.0016           37.68s\n",
      "        70           0.2399           0.0016           37.52s\n",
      "        80           0.2258           0.0016           36.81s\n",
      "        90           0.2203           0.0007           36.31s\n",
      "       100           0.1876           0.0002           35.79s\n",
      "       200           0.1170          -0.0001           31.67s\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "lr = 0.05\n",
      "0.9146183699870634\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      bangla       0.92      0.94      0.93       360\n",
      "   malayalam       0.90      0.91      0.90       601\n",
      "       odiya       0.94      0.92      0.93       190\n",
      "      telugu       0.93      0.90      0.92       395\n",
      "\n",
      "    accuracy                           0.91      1546\n",
      "   macro avg       0.92      0.92      0.92      1546\n",
      "weighted avg       0.91      0.91      0.91      1546\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           1.1439           0.1577           38.61s\n",
      "         2           1.0294           0.1063           39.83s\n",
      "         3           0.9305           0.0952           39.17s\n",
      "         4           0.8472           0.0786           38.73s\n",
      "         5           0.7717           0.0716           38.52s\n",
      "         6           0.7179           0.0594           38.77s\n",
      "         7           0.6657           0.0447           38.58s\n",
      "         8           0.6217           0.0390           38.33s\n",
      "         9           0.5616           0.0388           38.18s\n",
      "        10           0.5526           0.0317           37.96s\n",
      "        20           0.3369           0.0088           37.07s\n",
      "        30           0.2764           0.0029           37.37s\n",
      "        40           0.2110           0.0016           37.04s\n",
      "        50           0.2037           0.0014           36.41s\n",
      "        60           0.1742           0.0005           35.81s\n",
      "        70           0.1462           0.0005           35.32s\n",
      "        80           0.1299          -0.0001           35.18s\n",
      "        90           0.1333           0.0005           35.19s\n",
      "       100           0.1189          -0.0002           35.44s\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "lr = 0.1\n",
      "0.907503234152652\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      bangla       0.91      0.94      0.92       360\n",
      "   malayalam       0.89      0.89      0.89       601\n",
      "       odiya       0.95      0.91      0.92       190\n",
      "      telugu       0.92      0.91      0.91       395\n",
      "\n",
      "    accuracy                           0.91      1546\n",
      "   macro avg       0.91      0.91      0.91      1546\n",
      "weighted avg       0.91      0.91      0.91      1546\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.9976           0.2855           55.78s\n",
      "         2           0.8147           0.1724           53.19s\n",
      "         3           0.6887           0.1220           50.17s\n",
      "         4           0.6025           0.0921           46.93s\n",
      "         5           0.5200           0.0591           45.27s\n",
      "         6           0.4766           0.0489           44.27s\n",
      "         7           0.4359           0.0397           43.55s\n",
      "         8           0.4013           0.0313           44.72s\n",
      "         9           0.3561           0.0293           44.24s\n",
      "        10           0.3499           0.0164           43.96s\n",
      "        20           0.3758           0.0023           40.83s\n",
      "        30           0.2520           0.0005           39.26s\n",
      "        40           0.1389           0.0001           38.23s\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "lr = 0.2\n",
      "0.9036222509702458\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      bangla       0.92      0.92      0.92       360\n",
      "   malayalam       0.89      0.90      0.89       601\n",
      "       odiya       0.90      0.88      0.89       190\n",
      "      telugu       0.91      0.90      0.91       395\n",
      "\n",
      "    accuracy                           0.90      1546\n",
      "   macro avg       0.91      0.90      0.90      1546\n",
      "weighted avg       0.90      0.90      0.90      1546\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.8923           0.3608           40.45s\n",
      "         2           0.7091           0.1790           43.76s\n",
      "         3           0.6230           0.1039           42.76s\n",
      "         4           0.5491           0.0771           41.95s\n",
      "         5           0.4582           0.0573           41.70s\n",
      "         6           0.4044           0.0441           42.57s\n",
      "         7           0.3942           0.0324           41.66s\n",
      "         8           0.3477           0.0270           41.10s\n",
      "         9           0.3508           0.0191           40.70s\n",
      "        10           0.3014           0.0191           40.30s\n",
      "        20           0.1893           0.0008           38.63s\n",
      "        30           1.5991           0.0012           38.07s\n",
      "        40           4.5135          -0.0000           37.50s\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "lr = 0.25\n",
      "0.8906856403622251\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      bangla       0.89      0.93      0.91       360\n",
      "   malayalam       0.87      0.88      0.88       601\n",
      "       odiya       0.90      0.88      0.89       190\n",
      "      telugu       0.91      0.88      0.89       395\n",
      "\n",
      "    accuracy                           0.89      1546\n",
      "   macro avg       0.89      0.89      0.89      1546\n",
      "weighted avg       0.89      0.89      0.89      1546\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.8681           0.3938           39.14s\n",
      "         2           0.6719           0.1898           38.83s\n",
      "         3           0.5715           0.1132           38.64s\n",
      "         4           0.4933           0.0780           38.15s\n",
      "         5           0.4427           0.0546           37.65s\n",
      "         6           0.3741           0.0325           37.84s\n",
      "         7           0.3597           0.0287           37.92s\n",
      "         8           0.3041           0.0141           37.82s\n",
      "         9           0.3056           0.0139           37.90s\n",
      "        10           0.2833           0.0100           38.23s\n",
      "        20           0.2029           0.0001           37.35s\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "lr = 0.3\n",
      "0.8880983182406209\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      bangla       0.89      0.91      0.90       360\n",
      "   malayalam       0.88      0.88      0.88       601\n",
      "       odiya       0.88      0.88      0.88       190\n",
      "      telugu       0.91      0.89      0.90       395\n",
      "\n",
      "    accuracy                           0.89      1546\n",
      "   macro avg       0.89      0.89      0.89      1546\n",
      "weighted avg       0.89      0.89      0.89      1546\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.7471           0.4993           39.19s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         2           0.5667           0.1893           42.32s\n",
      "         3           0.4586           0.1045           41.56s\n",
      "         4           0.3943           0.0664           40.42s\n",
      "         5           0.3232           0.0359           39.65s\n",
      "         6           0.3111           0.0230           39.24s\n",
      "         7           0.2600           0.0103           38.80s\n",
      "         8           0.2621           0.0043           39.28s\n",
      "         9           0.2353          -0.0363           39.18s\n",
      "        10           0.2543          -0.0062           38.82s\n",
      "        20           6.4895          -0.0008           38.12s\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "lr = 0.4\n",
      "0.8745148771021992\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      bangla       0.87      0.93      0.90       360\n",
      "   malayalam       0.87      0.85      0.86       601\n",
      "       odiya       0.85      0.82      0.83       190\n",
      "      telugu       0.90      0.89      0.89       395\n",
      "\n",
      "    accuracy                           0.87      1546\n",
      "   macro avg       0.87      0.87      0.87      1546\n",
      "weighted avg       0.87      0.87      0.87      1546\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.6596           0.6025           38.13s\n",
      "         2           0.4779           0.1590           37.98s\n",
      "         3           0.3644           0.0925           37.62s\n",
      "         4           0.3248           0.0293           37.49s\n",
      "         5           0.2872           0.0288           37.34s\n",
      "         6           0.2574           0.0121           37.43s\n",
      "         7           0.2575          -0.0031           37.48s\n",
      "         8           0.2351           0.0127           37.27s\n",
      "         9           0.2166          -6.0736           37.09s\n",
      "        10           9.9069           0.0014           36.88s\n",
      "        20           2.5362     -104957.0099           36.16s\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "lr = 0.5\n",
      "0.8622250970245796\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      bangla       0.87      0.92      0.89       360\n",
      "   malayalam       0.85      0.83      0.84       601\n",
      "       odiya       0.81      0.86      0.84       190\n",
      "      telugu       0.90      0.87      0.89       395\n",
      "\n",
      "    accuracy                           0.86      1546\n",
      "   macro avg       0.86      0.87      0.86      1546\n",
      "weighted avg       0.86      0.86      0.86      1546\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "lr_list = [0.05, 0.1, 0.2, 0.25, 0.3, 0.4, 0.5]\n",
    "for lr in lr_list:\n",
    "    model_gbm = GradientBoostingClassifier(n_estimators=1000,\n",
    "                                           learning_rate=lr,\n",
    "                                           max_depth=4,\n",
    "                                           subsample=0.3,\n",
    "                                           validation_fraction=0.1,\n",
    "                                           n_iter_no_change=20,\n",
    "                                           max_features='log2',\n",
    "                                           verbose=1)\n",
    "    model_gbm.fit(train_features, train_labels)\n",
    "    print('---------------------------------------------------------------------------------------------------------')\n",
    "    print('lr =', lr)\n",
    "    print(model_gbm.score(test_features, test_labels))\n",
    "    print('---------------------------------------------------------------------------------------------------------')\n",
    "    print(classification_report(test_labels,model_gbm.predict(test_features)))\n",
    "    print('---------------------------------------------------------------------------------------------------------')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b4ea317f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[330  25   1   4]\n",
      " [ 38 496  34  33]\n",
      " [  0  27 163   0]\n",
      " [ 13  36   2 344]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(test_labels,model_gbm.predict(test_features)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
