{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f1f68c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "110438f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import IPython.display as ipd\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import random\n",
    "import pandas as pd\n",
    "from statistics import mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "058d4080",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_json('../4_accent_features_22k.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a24526a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lable</th>\n",
       "      <th>rms</th>\n",
       "      <th>zrc</th>\n",
       "      <th>sb</th>\n",
       "      <th>sc</th>\n",
       "      <th>mfcc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bangla</td>\n",
       "      <td>[0.0013946438000000002, 0.0020170733, 0.001862...</td>\n",
       "      <td>[0.0380859375, 0.083984375, 0.109375, 0.112304...</td>\n",
       "      <td>[2886.401524858, 2796.0275535111, 2909.4122465...</td>\n",
       "      <td>[2388.1567998945, 2180.9140804113, 2443.847420...</td>\n",
       "      <td>[[-471.7465515137, -456.7153930664, -459.34436...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>malayalam</td>\n",
       "      <td>[0.0018541168000000001, 0.0027880995, 0.002781...</td>\n",
       "      <td>[0.0302734375, 0.0654296875, 0.078125, 0.08007...</td>\n",
       "      <td>[2678.5589162968, 2631.4120034514, 2610.859365...</td>\n",
       "      <td>[1946.2487991002, 2028.1892441629, 2041.918837...</td>\n",
       "      <td>[[-472.3463745117, -446.223815918, -440.630249...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>malayalam</td>\n",
       "      <td>[0.0020720728, 0.002927064, 0.0027094684, 0.00...</td>\n",
       "      <td>[0.0419921875, 0.078125, 0.0654296875, 0.08300...</td>\n",
       "      <td>[2891.4828893877, 2809.1249499908, 2620.486954...</td>\n",
       "      <td>[2412.3271069461, 2277.5214977171, 1993.719309...</td>\n",
       "      <td>[[-476.6443786621, -446.4409484863, -445.25283...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>odiya</td>\n",
       "      <td>[0.0016051014, 0.0025093982, 0.002824514200000...</td>\n",
       "      <td>[0.0400390625, 0.072265625, 0.0615234375, 0.07...</td>\n",
       "      <td>[2697.6979899722, 2628.8437120369, 2626.839185...</td>\n",
       "      <td>[2141.7725273933, 2088.7253072531, 2009.974668...</td>\n",
       "      <td>[[-477.852935791, -448.7857971191, -444.822631...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bangla</td>\n",
       "      <td>[0.0019763573, 0.0027296843, 0.003020898200000...</td>\n",
       "      <td>[0.0400390625, 0.0771484375, 0.0791015625, 0.0...</td>\n",
       "      <td>[2468.2086847496, 2488.7754963086, 2448.232229...</td>\n",
       "      <td>[1936.6119578417, 2079.1606236968, 1945.780888...</td>\n",
       "      <td>[[-446.6452941895, -422.6954345703, -426.02734...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6178</th>\n",
       "      <td>telugu</td>\n",
       "      <td>[0.0013207975, 0.0019568782, 0.002198813, 0.03...</td>\n",
       "      <td>[0.0400390625, 0.0810546875, 0.078125, 0.06542...</td>\n",
       "      <td>[2781.7079534371, 2721.4191785234, 2722.215196...</td>\n",
       "      <td>[2389.1352454214, 2151.9468806418, 2232.123016...</td>\n",
       "      <td>[[-494.7901000977, -458.7627563477, -429.15322...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6179</th>\n",
       "      <td>odiya</td>\n",
       "      <td>[0.0017946149, 0.0026038224, 0.0033023616, 0.0...</td>\n",
       "      <td>[0.0546875, 0.1015625, 0.076171875, 0.06347656...</td>\n",
       "      <td>[2817.6374684681, 2590.470282003, 2535.3186567...</td>\n",
       "      <td>[2697.3529675747, 2111.9722581644, 1928.624935...</td>\n",
       "      <td>[[-471.3420715332, -423.157043457, -421.175170...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6180</th>\n",
       "      <td>malayalam</td>\n",
       "      <td>[0.0017542240000000002, 0.0025207074, 0.002529...</td>\n",
       "      <td>[0.033203125, 0.05859375, 0.0498046875, 0.0722...</td>\n",
       "      <td>[2792.8350576795, 2739.9685261638, 2786.457334...</td>\n",
       "      <td>[2366.7544940406, 2108.1867222711, 2258.360337...</td>\n",
       "      <td>[[-488.4339599609, -459.7818603516, -461.59078...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6181</th>\n",
       "      <td>bangla</td>\n",
       "      <td>[0.0014164349000000001, 0.0019143918000000002,...</td>\n",
       "      <td>[0.0390625, 0.09375000000000001, 0.1005859375,...</td>\n",
       "      <td>[2767.9994245806, 2828.1800438228, 2766.121219...</td>\n",
       "      <td>[2193.7947199968, 2402.7724275448, 2370.159846...</td>\n",
       "      <td>[[-490.4011535645, -462.4995422363, -463.83020...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6182</th>\n",
       "      <td>telugu</td>\n",
       "      <td>[0.0484213158, 0.06314402820000001, 0.05158800...</td>\n",
       "      <td>[0.009765625, 0.015625, 0.015625, 0.03125, 0.0...</td>\n",
       "      <td>[1486.085447337, 1078.1197341638, 1242.7112051...</td>\n",
       "      <td>[713.7242808265, 461.0879906932, 511.009573229...</td>\n",
       "      <td>[[-332.3883056641, -366.9843444824, -323.56549...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6183 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          lable                                                rms  \\\n",
       "0        bangla  [0.0013946438000000002, 0.0020170733, 0.001862...   \n",
       "1     malayalam  [0.0018541168000000001, 0.0027880995, 0.002781...   \n",
       "2     malayalam  [0.0020720728, 0.002927064, 0.0027094684, 0.00...   \n",
       "3         odiya  [0.0016051014, 0.0025093982, 0.002824514200000...   \n",
       "4        bangla  [0.0019763573, 0.0027296843, 0.003020898200000...   \n",
       "...         ...                                                ...   \n",
       "6178     telugu  [0.0013207975, 0.0019568782, 0.002198813, 0.03...   \n",
       "6179      odiya  [0.0017946149, 0.0026038224, 0.0033023616, 0.0...   \n",
       "6180  malayalam  [0.0017542240000000002, 0.0025207074, 0.002529...   \n",
       "6181     bangla  [0.0014164349000000001, 0.0019143918000000002,...   \n",
       "6182     telugu  [0.0484213158, 0.06314402820000001, 0.05158800...   \n",
       "\n",
       "                                                    zrc  \\\n",
       "0     [0.0380859375, 0.083984375, 0.109375, 0.112304...   \n",
       "1     [0.0302734375, 0.0654296875, 0.078125, 0.08007...   \n",
       "2     [0.0419921875, 0.078125, 0.0654296875, 0.08300...   \n",
       "3     [0.0400390625, 0.072265625, 0.0615234375, 0.07...   \n",
       "4     [0.0400390625, 0.0771484375, 0.0791015625, 0.0...   \n",
       "...                                                 ...   \n",
       "6178  [0.0400390625, 0.0810546875, 0.078125, 0.06542...   \n",
       "6179  [0.0546875, 0.1015625, 0.076171875, 0.06347656...   \n",
       "6180  [0.033203125, 0.05859375, 0.0498046875, 0.0722...   \n",
       "6181  [0.0390625, 0.09375000000000001, 0.1005859375,...   \n",
       "6182  [0.009765625, 0.015625, 0.015625, 0.03125, 0.0...   \n",
       "\n",
       "                                                     sb  \\\n",
       "0     [2886.401524858, 2796.0275535111, 2909.4122465...   \n",
       "1     [2678.5589162968, 2631.4120034514, 2610.859365...   \n",
       "2     [2891.4828893877, 2809.1249499908, 2620.486954...   \n",
       "3     [2697.6979899722, 2628.8437120369, 2626.839185...   \n",
       "4     [2468.2086847496, 2488.7754963086, 2448.232229...   \n",
       "...                                                 ...   \n",
       "6178  [2781.7079534371, 2721.4191785234, 2722.215196...   \n",
       "6179  [2817.6374684681, 2590.470282003, 2535.3186567...   \n",
       "6180  [2792.8350576795, 2739.9685261638, 2786.457334...   \n",
       "6181  [2767.9994245806, 2828.1800438228, 2766.121219...   \n",
       "6182  [1486.085447337, 1078.1197341638, 1242.7112051...   \n",
       "\n",
       "                                                     sc  \\\n",
       "0     [2388.1567998945, 2180.9140804113, 2443.847420...   \n",
       "1     [1946.2487991002, 2028.1892441629, 2041.918837...   \n",
       "2     [2412.3271069461, 2277.5214977171, 1993.719309...   \n",
       "3     [2141.7725273933, 2088.7253072531, 2009.974668...   \n",
       "4     [1936.6119578417, 2079.1606236968, 1945.780888...   \n",
       "...                                                 ...   \n",
       "6178  [2389.1352454214, 2151.9468806418, 2232.123016...   \n",
       "6179  [2697.3529675747, 2111.9722581644, 1928.624935...   \n",
       "6180  [2366.7544940406, 2108.1867222711, 2258.360337...   \n",
       "6181  [2193.7947199968, 2402.7724275448, 2370.159846...   \n",
       "6182  [713.7242808265, 461.0879906932, 511.009573229...   \n",
       "\n",
       "                                                   mfcc  \n",
       "0     [[-471.7465515137, -456.7153930664, -459.34436...  \n",
       "1     [[-472.3463745117, -446.223815918, -440.630249...  \n",
       "2     [[-476.6443786621, -446.4409484863, -445.25283...  \n",
       "3     [[-477.852935791, -448.7857971191, -444.822631...  \n",
       "4     [[-446.6452941895, -422.6954345703, -426.02734...  \n",
       "...                                                 ...  \n",
       "6178  [[-494.7901000977, -458.7627563477, -429.15322...  \n",
       "6179  [[-471.3420715332, -423.157043457, -421.175170...  \n",
       "6180  [[-488.4339599609, -459.7818603516, -461.59078...  \n",
       "6181  [[-490.4011535645, -462.4995422363, -463.83020...  \n",
       "6182  [[-332.3883056641, -366.9843444824, -323.56549...  \n",
       "\n",
       "[6183 rows x 6 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fbd1f5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_min_avg_max_std(column, data=data):\n",
    "    row_data_min, row_data_avg, row_data_max, row_data_std = [], [], [], []\n",
    "    for row in data[column]:\n",
    "        row_data_min.append(min(row))\n",
    "        row_data_avg.append(mean(row))\n",
    "        row_data_max.append(max(row))\n",
    "        row_data_std.append(np.std(row))\n",
    "    \n",
    "    data.drop(column, axis=1, inplace=True)\n",
    "    data[f'min_{column}'] = row_data_min\n",
    "    data[f'avg_{column}'] = row_data_avg\n",
    "    data[f'max_{column}'] = row_data_max\n",
    "    data[f'std_{column}'] = row_data_std\n",
    "    \n",
    "    return row_data_min, row_data_avg, row_data_max, row_data_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08903337",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_min_avg_max_std('rms')\n",
    "get_min_avg_max_std('zrc')\n",
    "get_min_avg_max_std('sb')\n",
    "_ = get_min_avg_max_std('sc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4eb85588",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lable</th>\n",
       "      <th>min_rms</th>\n",
       "      <th>avg_rms</th>\n",
       "      <th>max_rms</th>\n",
       "      <th>std_rms</th>\n",
       "      <th>min_zrc</th>\n",
       "      <th>avg_zrc</th>\n",
       "      <th>max_zrc</th>\n",
       "      <th>std_zrc</th>\n",
       "      <th>min_sb</th>\n",
       "      <th>avg_sb</th>\n",
       "      <th>max_sb</th>\n",
       "      <th>std_sb</th>\n",
       "      <th>min_sc</th>\n",
       "      <th>avg_sc</th>\n",
       "      <th>max_sc</th>\n",
       "      <th>std_sc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bangla</td>\n",
       "      <td>0.001395</td>\n",
       "      <td>0.086223</td>\n",
       "      <td>0.292426</td>\n",
       "      <td>0.089146</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.154839</td>\n",
       "      <td>0.728516</td>\n",
       "      <td>0.174617</td>\n",
       "      <td>690.435133</td>\n",
       "      <td>2202.139263</td>\n",
       "      <td>3778.894295</td>\n",
       "      <td>769.614651</td>\n",
       "      <td>450.437122</td>\n",
       "      <td>2555.452742</td>\n",
       "      <td>7573.473501</td>\n",
       "      <td>1777.381675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>malayalam</td>\n",
       "      <td>0.001854</td>\n",
       "      <td>0.051283</td>\n",
       "      <td>0.201747</td>\n",
       "      <td>0.069206</td>\n",
       "      <td>0.017578</td>\n",
       "      <td>0.100883</td>\n",
       "      <td>0.664062</td>\n",
       "      <td>0.120811</td>\n",
       "      <td>840.251371</td>\n",
       "      <td>2266.859190</td>\n",
       "      <td>3728.589663</td>\n",
       "      <td>697.594885</td>\n",
       "      <td>512.745162</td>\n",
       "      <td>2078.347464</td>\n",
       "      <td>7123.439391</td>\n",
       "      <td>1325.738244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>malayalam</td>\n",
       "      <td>0.001721</td>\n",
       "      <td>0.020130</td>\n",
       "      <td>0.136092</td>\n",
       "      <td>0.027457</td>\n",
       "      <td>0.016602</td>\n",
       "      <td>0.114834</td>\n",
       "      <td>0.635742</td>\n",
       "      <td>0.125779</td>\n",
       "      <td>1225.640372</td>\n",
       "      <td>2397.933800</td>\n",
       "      <td>3083.726345</td>\n",
       "      <td>476.647974</td>\n",
       "      <td>585.840174</td>\n",
       "      <td>2287.418665</td>\n",
       "      <td>7209.135808</td>\n",
       "      <td>1292.383515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>odiya</td>\n",
       "      <td>0.001605</td>\n",
       "      <td>0.014365</td>\n",
       "      <td>0.085764</td>\n",
       "      <td>0.019914</td>\n",
       "      <td>0.016602</td>\n",
       "      <td>0.072445</td>\n",
       "      <td>0.332031</td>\n",
       "      <td>0.040311</td>\n",
       "      <td>1065.024228</td>\n",
       "      <td>2327.249148</td>\n",
       "      <td>3061.177303</td>\n",
       "      <td>527.385962</td>\n",
       "      <td>551.961391</td>\n",
       "      <td>1844.255336</td>\n",
       "      <td>4871.640815</td>\n",
       "      <td>635.829463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bangla</td>\n",
       "      <td>0.001976</td>\n",
       "      <td>0.052965</td>\n",
       "      <td>0.204123</td>\n",
       "      <td>0.064818</td>\n",
       "      <td>0.016602</td>\n",
       "      <td>0.080566</td>\n",
       "      <td>0.602539</td>\n",
       "      <td>0.080929</td>\n",
       "      <td>706.835106</td>\n",
       "      <td>2042.273991</td>\n",
       "      <td>3649.956346</td>\n",
       "      <td>698.445618</td>\n",
       "      <td>447.082234</td>\n",
       "      <td>1774.222759</td>\n",
       "      <td>7000.516471</td>\n",
       "      <td>1096.619444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6178</th>\n",
       "      <td>telugu</td>\n",
       "      <td>0.001321</td>\n",
       "      <td>0.046776</td>\n",
       "      <td>0.136986</td>\n",
       "      <td>0.043277</td>\n",
       "      <td>0.009766</td>\n",
       "      <td>0.059961</td>\n",
       "      <td>0.504883</td>\n",
       "      <td>0.066894</td>\n",
       "      <td>875.196785</td>\n",
       "      <td>1888.312374</td>\n",
       "      <td>2896.844442</td>\n",
       "      <td>718.350436</td>\n",
       "      <td>441.360981</td>\n",
       "      <td>1468.854314</td>\n",
       "      <td>5380.341401</td>\n",
       "      <td>1003.866597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6179</th>\n",
       "      <td>odiya</td>\n",
       "      <td>0.001795</td>\n",
       "      <td>0.019663</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>0.024542</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.082088</td>\n",
       "      <td>0.425781</td>\n",
       "      <td>0.067862</td>\n",
       "      <td>1175.091343</td>\n",
       "      <td>2320.185029</td>\n",
       "      <td>3639.743682</td>\n",
       "      <td>536.114902</td>\n",
       "      <td>574.554555</td>\n",
       "      <td>1934.522800</td>\n",
       "      <td>5186.208055</td>\n",
       "      <td>839.867478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6180</th>\n",
       "      <td>malayalam</td>\n",
       "      <td>0.001380</td>\n",
       "      <td>0.030098</td>\n",
       "      <td>0.170651</td>\n",
       "      <td>0.044062</td>\n",
       "      <td>0.013672</td>\n",
       "      <td>0.085098</td>\n",
       "      <td>0.390625</td>\n",
       "      <td>0.054994</td>\n",
       "      <td>779.022654</td>\n",
       "      <td>2310.245655</td>\n",
       "      <td>3255.817300</td>\n",
       "      <td>682.494239</td>\n",
       "      <td>511.193899</td>\n",
       "      <td>2015.218670</td>\n",
       "      <td>4854.653620</td>\n",
       "      <td>775.001160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6181</th>\n",
       "      <td>bangla</td>\n",
       "      <td>0.001398</td>\n",
       "      <td>0.057666</td>\n",
       "      <td>0.224636</td>\n",
       "      <td>0.075785</td>\n",
       "      <td>0.017578</td>\n",
       "      <td>0.122231</td>\n",
       "      <td>0.790039</td>\n",
       "      <td>0.142520</td>\n",
       "      <td>703.419893</td>\n",
       "      <td>2305.310919</td>\n",
       "      <td>3807.206322</td>\n",
       "      <td>805.059077</td>\n",
       "      <td>456.136777</td>\n",
       "      <td>2289.051523</td>\n",
       "      <td>7645.426565</td>\n",
       "      <td>1458.246269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6182</th>\n",
       "      <td>telugu</td>\n",
       "      <td>0.001465</td>\n",
       "      <td>0.047487</td>\n",
       "      <td>0.239017</td>\n",
       "      <td>0.063613</td>\n",
       "      <td>0.009766</td>\n",
       "      <td>0.068735</td>\n",
       "      <td>0.240234</td>\n",
       "      <td>0.036307</td>\n",
       "      <td>741.533559</td>\n",
       "      <td>2210.645469</td>\n",
       "      <td>3123.318353</td>\n",
       "      <td>739.603170</td>\n",
       "      <td>452.790201</td>\n",
       "      <td>1738.376381</td>\n",
       "      <td>3814.649679</td>\n",
       "      <td>828.149737</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6183 rows Ã— 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          lable   min_rms   avg_rms   max_rms   std_rms   min_zrc   avg_zrc  \\\n",
       "0        bangla  0.001395  0.086223  0.292426  0.089146  0.015625  0.154839   \n",
       "1     malayalam  0.001854  0.051283  0.201747  0.069206  0.017578  0.100883   \n",
       "2     malayalam  0.001721  0.020130  0.136092  0.027457  0.016602  0.114834   \n",
       "3         odiya  0.001605  0.014365  0.085764  0.019914  0.016602  0.072445   \n",
       "4        bangla  0.001976  0.052965  0.204123  0.064818  0.016602  0.080566   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "6178     telugu  0.001321  0.046776  0.136986  0.043277  0.009766  0.059961   \n",
       "6179      odiya  0.001795  0.019663  0.090794  0.024542  0.015625  0.082088   \n",
       "6180  malayalam  0.001380  0.030098  0.170651  0.044062  0.013672  0.085098   \n",
       "6181     bangla  0.001398  0.057666  0.224636  0.075785  0.017578  0.122231   \n",
       "6182     telugu  0.001465  0.047487  0.239017  0.063613  0.009766  0.068735   \n",
       "\n",
       "       max_zrc   std_zrc       min_sb       avg_sb       max_sb      std_sb  \\\n",
       "0     0.728516  0.174617   690.435133  2202.139263  3778.894295  769.614651   \n",
       "1     0.664062  0.120811   840.251371  2266.859190  3728.589663  697.594885   \n",
       "2     0.635742  0.125779  1225.640372  2397.933800  3083.726345  476.647974   \n",
       "3     0.332031  0.040311  1065.024228  2327.249148  3061.177303  527.385962   \n",
       "4     0.602539  0.080929   706.835106  2042.273991  3649.956346  698.445618   \n",
       "...        ...       ...          ...          ...          ...         ...   \n",
       "6178  0.504883  0.066894   875.196785  1888.312374  2896.844442  718.350436   \n",
       "6179  0.425781  0.067862  1175.091343  2320.185029  3639.743682  536.114902   \n",
       "6180  0.390625  0.054994   779.022654  2310.245655  3255.817300  682.494239   \n",
       "6181  0.790039  0.142520   703.419893  2305.310919  3807.206322  805.059077   \n",
       "6182  0.240234  0.036307   741.533559  2210.645469  3123.318353  739.603170   \n",
       "\n",
       "          min_sc       avg_sc       max_sc       std_sc  \n",
       "0     450.437122  2555.452742  7573.473501  1777.381675  \n",
       "1     512.745162  2078.347464  7123.439391  1325.738244  \n",
       "2     585.840174  2287.418665  7209.135808  1292.383515  \n",
       "3     551.961391  1844.255336  4871.640815   635.829463  \n",
       "4     447.082234  1774.222759  7000.516471  1096.619444  \n",
       "...          ...          ...          ...          ...  \n",
       "6178  441.360981  1468.854314  5380.341401  1003.866597  \n",
       "6179  574.554555  1934.522800  5186.208055   839.867478  \n",
       "6180  511.193899  2015.218670  4854.653620   775.001160  \n",
       "6181  456.136777  2289.051523  7645.426565  1458.246269  \n",
       "6182  452.790201  1738.376381  3814.649679   828.149737  \n",
       "\n",
       "[6183 rows x 17 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.drop('mfcc', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "87a4b17c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>min_rms</th>\n",
       "      <th>avg_rms</th>\n",
       "      <th>max_rms</th>\n",
       "      <th>std_rms</th>\n",
       "      <th>min_zrc</th>\n",
       "      <th>avg_zrc</th>\n",
       "      <th>max_zrc</th>\n",
       "      <th>std_zrc</th>\n",
       "      <th>min_sb</th>\n",
       "      <th>avg_sb</th>\n",
       "      <th>max_sb</th>\n",
       "      <th>std_sb</th>\n",
       "      <th>min_sc</th>\n",
       "      <th>avg_sc</th>\n",
       "      <th>max_sc</th>\n",
       "      <th>std_sc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001395</td>\n",
       "      <td>0.086223</td>\n",
       "      <td>0.292426</td>\n",
       "      <td>0.089146</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.154839</td>\n",
       "      <td>0.728516</td>\n",
       "      <td>0.174617</td>\n",
       "      <td>690.435133</td>\n",
       "      <td>2202.139263</td>\n",
       "      <td>3778.894295</td>\n",
       "      <td>769.614651</td>\n",
       "      <td>450.437122</td>\n",
       "      <td>2555.452742</td>\n",
       "      <td>7573.473501</td>\n",
       "      <td>1777.381675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001854</td>\n",
       "      <td>0.051283</td>\n",
       "      <td>0.201747</td>\n",
       "      <td>0.069206</td>\n",
       "      <td>0.017578</td>\n",
       "      <td>0.100883</td>\n",
       "      <td>0.664062</td>\n",
       "      <td>0.120811</td>\n",
       "      <td>840.251371</td>\n",
       "      <td>2266.859190</td>\n",
       "      <td>3728.589663</td>\n",
       "      <td>697.594885</td>\n",
       "      <td>512.745162</td>\n",
       "      <td>2078.347464</td>\n",
       "      <td>7123.439391</td>\n",
       "      <td>1325.738244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001721</td>\n",
       "      <td>0.020130</td>\n",
       "      <td>0.136092</td>\n",
       "      <td>0.027457</td>\n",
       "      <td>0.016602</td>\n",
       "      <td>0.114834</td>\n",
       "      <td>0.635742</td>\n",
       "      <td>0.125779</td>\n",
       "      <td>1225.640372</td>\n",
       "      <td>2397.933800</td>\n",
       "      <td>3083.726345</td>\n",
       "      <td>476.647974</td>\n",
       "      <td>585.840174</td>\n",
       "      <td>2287.418665</td>\n",
       "      <td>7209.135808</td>\n",
       "      <td>1292.383515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001605</td>\n",
       "      <td>0.014365</td>\n",
       "      <td>0.085764</td>\n",
       "      <td>0.019914</td>\n",
       "      <td>0.016602</td>\n",
       "      <td>0.072445</td>\n",
       "      <td>0.332031</td>\n",
       "      <td>0.040311</td>\n",
       "      <td>1065.024228</td>\n",
       "      <td>2327.249148</td>\n",
       "      <td>3061.177303</td>\n",
       "      <td>527.385962</td>\n",
       "      <td>551.961391</td>\n",
       "      <td>1844.255336</td>\n",
       "      <td>4871.640815</td>\n",
       "      <td>635.829463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001976</td>\n",
       "      <td>0.052965</td>\n",
       "      <td>0.204123</td>\n",
       "      <td>0.064818</td>\n",
       "      <td>0.016602</td>\n",
       "      <td>0.080566</td>\n",
       "      <td>0.602539</td>\n",
       "      <td>0.080929</td>\n",
       "      <td>706.835106</td>\n",
       "      <td>2042.273991</td>\n",
       "      <td>3649.956346</td>\n",
       "      <td>698.445618</td>\n",
       "      <td>447.082234</td>\n",
       "      <td>1774.222759</td>\n",
       "      <td>7000.516471</td>\n",
       "      <td>1096.619444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6178</th>\n",
       "      <td>0.001321</td>\n",
       "      <td>0.046776</td>\n",
       "      <td>0.136986</td>\n",
       "      <td>0.043277</td>\n",
       "      <td>0.009766</td>\n",
       "      <td>0.059961</td>\n",
       "      <td>0.504883</td>\n",
       "      <td>0.066894</td>\n",
       "      <td>875.196785</td>\n",
       "      <td>1888.312374</td>\n",
       "      <td>2896.844442</td>\n",
       "      <td>718.350436</td>\n",
       "      <td>441.360981</td>\n",
       "      <td>1468.854314</td>\n",
       "      <td>5380.341401</td>\n",
       "      <td>1003.866597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6179</th>\n",
       "      <td>0.001795</td>\n",
       "      <td>0.019663</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>0.024542</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.082088</td>\n",
       "      <td>0.425781</td>\n",
       "      <td>0.067862</td>\n",
       "      <td>1175.091343</td>\n",
       "      <td>2320.185029</td>\n",
       "      <td>3639.743682</td>\n",
       "      <td>536.114902</td>\n",
       "      <td>574.554555</td>\n",
       "      <td>1934.522800</td>\n",
       "      <td>5186.208055</td>\n",
       "      <td>839.867478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6180</th>\n",
       "      <td>0.001380</td>\n",
       "      <td>0.030098</td>\n",
       "      <td>0.170651</td>\n",
       "      <td>0.044062</td>\n",
       "      <td>0.013672</td>\n",
       "      <td>0.085098</td>\n",
       "      <td>0.390625</td>\n",
       "      <td>0.054994</td>\n",
       "      <td>779.022654</td>\n",
       "      <td>2310.245655</td>\n",
       "      <td>3255.817300</td>\n",
       "      <td>682.494239</td>\n",
       "      <td>511.193899</td>\n",
       "      <td>2015.218670</td>\n",
       "      <td>4854.653620</td>\n",
       "      <td>775.001160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6181</th>\n",
       "      <td>0.001398</td>\n",
       "      <td>0.057666</td>\n",
       "      <td>0.224636</td>\n",
       "      <td>0.075785</td>\n",
       "      <td>0.017578</td>\n",
       "      <td>0.122231</td>\n",
       "      <td>0.790039</td>\n",
       "      <td>0.142520</td>\n",
       "      <td>703.419893</td>\n",
       "      <td>2305.310919</td>\n",
       "      <td>3807.206322</td>\n",
       "      <td>805.059077</td>\n",
       "      <td>456.136777</td>\n",
       "      <td>2289.051523</td>\n",
       "      <td>7645.426565</td>\n",
       "      <td>1458.246269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6182</th>\n",
       "      <td>0.001465</td>\n",
       "      <td>0.047487</td>\n",
       "      <td>0.239017</td>\n",
       "      <td>0.063613</td>\n",
       "      <td>0.009766</td>\n",
       "      <td>0.068735</td>\n",
       "      <td>0.240234</td>\n",
       "      <td>0.036307</td>\n",
       "      <td>741.533559</td>\n",
       "      <td>2210.645469</td>\n",
       "      <td>3123.318353</td>\n",
       "      <td>739.603170</td>\n",
       "      <td>452.790201</td>\n",
       "      <td>1738.376381</td>\n",
       "      <td>3814.649679</td>\n",
       "      <td>828.149737</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6183 rows Ã— 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       min_rms   avg_rms   max_rms   std_rms   min_zrc   avg_zrc   max_zrc  \\\n",
       "0     0.001395  0.086223  0.292426  0.089146  0.015625  0.154839  0.728516   \n",
       "1     0.001854  0.051283  0.201747  0.069206  0.017578  0.100883  0.664062   \n",
       "2     0.001721  0.020130  0.136092  0.027457  0.016602  0.114834  0.635742   \n",
       "3     0.001605  0.014365  0.085764  0.019914  0.016602  0.072445  0.332031   \n",
       "4     0.001976  0.052965  0.204123  0.064818  0.016602  0.080566  0.602539   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "6178  0.001321  0.046776  0.136986  0.043277  0.009766  0.059961  0.504883   \n",
       "6179  0.001795  0.019663  0.090794  0.024542  0.015625  0.082088  0.425781   \n",
       "6180  0.001380  0.030098  0.170651  0.044062  0.013672  0.085098  0.390625   \n",
       "6181  0.001398  0.057666  0.224636  0.075785  0.017578  0.122231  0.790039   \n",
       "6182  0.001465  0.047487  0.239017  0.063613  0.009766  0.068735  0.240234   \n",
       "\n",
       "       std_zrc       min_sb       avg_sb       max_sb      std_sb      min_sc  \\\n",
       "0     0.174617   690.435133  2202.139263  3778.894295  769.614651  450.437122   \n",
       "1     0.120811   840.251371  2266.859190  3728.589663  697.594885  512.745162   \n",
       "2     0.125779  1225.640372  2397.933800  3083.726345  476.647974  585.840174   \n",
       "3     0.040311  1065.024228  2327.249148  3061.177303  527.385962  551.961391   \n",
       "4     0.080929   706.835106  2042.273991  3649.956346  698.445618  447.082234   \n",
       "...        ...          ...          ...          ...         ...         ...   \n",
       "6178  0.066894   875.196785  1888.312374  2896.844442  718.350436  441.360981   \n",
       "6179  0.067862  1175.091343  2320.185029  3639.743682  536.114902  574.554555   \n",
       "6180  0.054994   779.022654  2310.245655  3255.817300  682.494239  511.193899   \n",
       "6181  0.142520   703.419893  2305.310919  3807.206322  805.059077  456.136777   \n",
       "6182  0.036307   741.533559  2210.645469  3123.318353  739.603170  452.790201   \n",
       "\n",
       "           avg_sc       max_sc       std_sc  \n",
       "0     2555.452742  7573.473501  1777.381675  \n",
       "1     2078.347464  7123.439391  1325.738244  \n",
       "2     2287.418665  7209.135808  1292.383515  \n",
       "3     1844.255336  4871.640815   635.829463  \n",
       "4     1774.222759  7000.516471  1096.619444  \n",
       "...           ...          ...          ...  \n",
       "6178  1468.854314  5380.341401  1003.866597  \n",
       "6179  1934.522800  5186.208055   839.867478  \n",
       "6180  2015.218670  4854.653620   775.001160  \n",
       "6181  2289.051523  7645.426565  1458.246269  \n",
       "6182  1738.376381  3814.649679   828.149737  \n",
       "\n",
       "[6183 rows x 16 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = data.drop(['lable', 'mfcc'], axis=1)\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc32abbb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['bangla', 'malayalam', 'malayalam', ..., 'malayalam', 'bangla',\n",
       "       'telugu'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lables = np.array(data['lable'])\n",
    "\n",
    "lables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e7f6f29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(features, lables, test_size = 0.25, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "73b28a95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4637, 16), (1546, 16), (4637,), (1546,))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.shape, test_features.shape, train_labels.shape, test_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dc13357b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           1.2211           0.0828           56.71s\n",
      "         2           1.1510           0.0747           42.80s\n",
      "         3           1.0798           0.0660           39.05s\n",
      "         4           1.0216           0.0555           34.59s\n",
      "         5           0.9564           0.0514           35.91s\n",
      "         6           0.9114           0.0486           33.57s\n",
      "         7           0.8779           0.0437           37.32s\n",
      "         8           0.8263           0.0384           35.38s\n",
      "         9           0.7872           0.0377           33.47s\n",
      "        10           0.7641           0.0336           32.35s\n",
      "        20           0.5135           0.0158           24.97s\n",
      "        30           0.3877           0.0082           22.13s\n",
      "        40           0.3070           0.0043           20.35s\n",
      "        50           0.2796           0.0028           19.17s\n",
      "        60           0.2481           0.0016           18.41s\n",
      "        70           0.1994           0.0012           17.68s\n",
      "        80           0.1883           0.0015           16.98s\n",
      "        90           0.1819           0.0007           16.39s\n",
      "       100           0.1787           0.0004           16.01s\n",
      "       200           0.0842           0.0000           13.67s\n",
      "       300           0.0527          -0.0001           11.59s\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "lr = 0.05\n",
      "0.9307891332470892\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      bangla       0.94      0.95      0.94       360\n",
      "   malayalam       0.91      0.92      0.92       601\n",
      "       odiya       0.95      0.92      0.93       190\n",
      "      telugu       0.95      0.93      0.94       395\n",
      "\n",
      "    accuracy                           0.93      1546\n",
      "   macro avg       0.94      0.93      0.93      1546\n",
      "weighted avg       0.93      0.93      0.93      1546\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           1.1336           0.1539           15.90s\n",
      "         2           1.0232           0.1179           17.44s\n",
      "         3           0.9162           0.1045           16.80s\n",
      "         4           0.8105           0.0874           16.47s\n",
      "         5           0.7590           0.0674           16.35s\n",
      "         6           0.6899           0.0590           16.25s\n",
      "         7           0.6418           0.0512           16.16s\n",
      "         8           0.5949           0.0450           15.85s\n",
      "         9           0.5295           0.0377           15.63s\n",
      "        10           0.5026           0.0329           15.42s\n",
      "        20           0.3118           0.0109           15.56s\n",
      "        30           0.2209           0.0041           15.16s\n",
      "        40           0.1863           0.0027           15.01s\n",
      "        50           0.1533           0.0010           14.82s\n",
      "        60           0.1409           0.0003           14.65s\n",
      "        70           0.1266           0.0002           14.64s\n",
      "        80           0.1065           0.0002           14.70s\n",
      "        90           0.0979           0.0001           14.52s\n",
      "       100           0.0840          -0.0002           14.12s\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "lr = 0.1\n",
      "0.9379042690815006\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      bangla       0.94      0.96      0.95       360\n",
      "   malayalam       0.93      0.93      0.93       601\n",
      "       odiya       0.96      0.94      0.95       190\n",
      "      telugu       0.95      0.93      0.94       395\n",
      "\n",
      "    accuracy                           0.94      1546\n",
      "   macro avg       0.94      0.94      0.94      1546\n",
      "weighted avg       0.94      0.94      0.94      1546\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.9517           0.3239           16.72s\n",
      "         2           0.7923           0.1685           16.69s\n",
      "         3           0.6848           0.1130           16.55s\n",
      "         4           0.5759           0.0927           16.72s\n",
      "         5           0.4978           0.0701           16.70s\n",
      "         6           0.4367           0.0469           16.52s\n",
      "         7           0.4173           0.0399           16.48s\n",
      "         8           0.3692           0.0303           16.86s\n",
      "         9           0.3436           0.0235           17.69s\n",
      "        10           0.3156           0.0219           17.60s\n",
      "        20           0.2038          -0.0053           17.46s\n",
      "        30           0.1396           0.0006           18.33s\n",
      "        40           0.1203           0.0002           18.70s\n",
      "        50           0.0872           0.0004           19.47s\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "lr = 0.2\n",
      "0.9223803363518758\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      bangla       0.92      0.95      0.93       360\n",
      "   malayalam       0.90      0.92      0.91       601\n",
      "       odiya       0.94      0.91      0.92       190\n",
      "      telugu       0.95      0.91      0.93       395\n",
      "\n",
      "    accuracy                           0.92      1546\n",
      "   macro avg       0.93      0.92      0.92      1546\n",
      "weighted avg       0.92      0.92      0.92      1546\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.8685           0.3720           19.08s\n",
      "         2           0.6851           0.1915           18.32s\n",
      "         3           0.5678           0.1233           18.31s\n",
      "         4           0.4975           0.0725           18.72s\n",
      "         5           0.4157           0.0619           18.45s\n",
      "         6           0.3762           0.0457           18.22s\n",
      "         7           0.3440           0.0336           17.93s\n",
      "         8           0.3040           0.0248           17.74s\n",
      "         9           0.2748           0.0213           17.88s\n",
      "        10           0.2691           0.0143           18.01s\n",
      "        20           0.1717           0.0017           18.16s\n",
      "        30           0.1210           0.0009           17.89s\n",
      "        40           0.0972          -0.0004           17.67s\n",
      "        50           0.0673          -0.0000           17.22s\n",
      "        60           0.0525          -0.0002           17.02s\n",
      "        70           0.0426          -0.0003           16.79s\n",
      "        80           0.0329          -0.0002           16.61s\n",
      "        90           0.0282          -0.0002           16.34s\n",
      "       100           0.0205          -0.0001           16.10s\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "lr = 0.25\n",
      "0.9398447606727037\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      bangla       0.93      0.95      0.94       360\n",
      "   malayalam       0.93      0.94      0.93       601\n",
      "       odiya       0.97      0.93      0.95       190\n",
      "      telugu       0.95      0.94      0.95       395\n",
      "\n",
      "    accuracy                           0.94      1546\n",
      "   macro avg       0.95      0.94      0.94      1546\n",
      "weighted avg       0.94      0.94      0.94      1546\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.8354           0.4439           12.42s\n",
      "         2           0.6423           0.1825           12.92s\n",
      "         3           0.5212           0.1212           12.82s\n",
      "         4           0.4312           0.0704           12.90s\n",
      "         5           0.3916           0.0460           12.89s\n",
      "         6           0.3365           0.0434           13.04s\n",
      "         7           0.2926           0.0273           13.08s\n",
      "         8           0.2749           0.0184           13.14s\n",
      "         9           0.2500           0.0083           13.24s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        10           0.2346           0.0119           13.39s\n",
      "        20           1.3235          -2.1894           13.93s\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "lr = 0.3\n",
      "0.908150064683053\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      bangla       0.91      0.95      0.93       360\n",
      "   malayalam       0.90      0.88      0.89       601\n",
      "       odiya       0.91      0.89      0.90       190\n",
      "      telugu       0.92      0.91      0.92       395\n",
      "\n",
      "    accuracy                           0.91      1546\n",
      "   macro avg       0.91      0.91      0.91      1546\n",
      "weighted avg       0.91      0.91      0.91      1546\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.7146           0.5092           15.41s\n",
      "         2           0.5540           0.2076           14.51s\n",
      "         3           0.4008           0.1040           14.39s\n",
      "         4           0.3430           0.0657           14.42s\n",
      "         5           0.2834           0.0450           14.56s\n",
      "         6           0.2642           0.0179           14.71s\n",
      "         7           0.2349           0.0167           14.77s\n",
      "         8           0.2218           0.0065           14.81s\n",
      "         9           0.2203           0.0079           14.81s\n",
      "        10           0.1875           0.0054           14.78s\n",
      "        20          21.2697          -0.0165           16.48s\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "lr = 0.4\n",
      "0.9010349288486417\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      bangla       0.90      0.93      0.91       360\n",
      "   malayalam       0.88      0.90      0.89       601\n",
      "       odiya       0.91      0.87      0.89       190\n",
      "      telugu       0.92      0.90      0.91       395\n",
      "\n",
      "    accuracy                           0.90      1546\n",
      "   macro avg       0.91      0.90      0.90      1546\n",
      "weighted avg       0.90      0.90      0.90      1546\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.6181           0.6154           14.21s\n",
      "         2           0.4390           0.1729           16.13s\n",
      "         3           0.3625           0.0776           16.57s\n",
      "         4           0.3069           0.0489           15.97s\n",
      "         5           0.2590           0.0135           15.42s\n",
      "         6           0.2377           0.0213           15.34s\n",
      "         7           0.2125          -0.0023           15.45s\n",
      "         8           0.1783          -0.0793           15.61s\n",
      "         9           0.2035           0.0115           15.71s\n",
      "        10           0.3527          -0.0049           15.46s\n",
      "        20         382.8848        -130.4725           14.23s\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "lr = 0.5\n",
      "0.88745148771022\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      bangla       0.89      0.93      0.91       360\n",
      "   malayalam       0.87      0.89      0.88       601\n",
      "       odiya       0.88      0.84      0.86       190\n",
      "      telugu       0.91      0.88      0.90       395\n",
      "\n",
      "    accuracy                           0.89      1546\n",
      "   macro avg       0.89      0.88      0.88      1546\n",
      "weighted avg       0.89      0.89      0.89      1546\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "lr_list = [0.05, 0.1, 0.2, 0.25, 0.3, 0.4, 0.5]\n",
    "for lr in lr_list:\n",
    "    model_gbm = GradientBoostingClassifier(n_estimators=1000,\n",
    "                                           learning_rate=lr,\n",
    "                                           max_depth=4,\n",
    "                                           subsample=0.3,\n",
    "                                           validation_fraction=0.1,\n",
    "                                           n_iter_no_change=20,\n",
    "                                           max_features='log2',\n",
    "                                           verbose=1)\n",
    "    model_gbm.fit(train_features, train_labels)\n",
    "    print('---------------------------------------------------------------------------------------------------------')\n",
    "    print('lr =', lr)\n",
    "    print(model_gbm.score(test_features, test_labels))\n",
    "    print('---------------------------------------------------------------------------------------------------------')\n",
    "    print(classification_report(test_labels,model_gbm.predict(test_features)))\n",
    "    print('---------------------------------------------------------------------------------------------------------')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b4ea317f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[333  20   1   6]\n",
      " [ 23 533  19  26]\n",
      " [  2  28 159   1]\n",
      " [ 17  29   2 347]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(test_labels,model_gbm.predict(test_features)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
